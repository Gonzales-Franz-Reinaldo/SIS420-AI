{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2Vq3sa2zu5Iu76ZnXFnOV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTCOCvAAfsRj","executionInfo":{"status":"ok","timestamp":1696438233176,"user_tz":240,"elapsed":3883,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"e20a2ed1-5c0a-40d5-deed-46122ba3bf5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1000/10000], Loss: 0.0625\n","Epoch [2000/10000], Loss: 0.0625\n","Epoch [3000/10000], Loss: 0.0625\n","Epoch [4000/10000], Loss: 0.0625\n","Epoch [5000/10000], Loss: 0.0625\n","Epoch [6000/10000], Loss: 0.0625\n","Epoch [7000/10000], Loss: 0.0625\n","Epoch [8000/10000], Loss: 0.0625\n","Epoch [9000/10000], Loss: 0.0625\n","Epoch [10000/10000], Loss: 0.0625\n","Predicciones finales:\n","Entrada: [0.0, 0.0], Predicción: -0.2500\n","Entrada: [0.0, 1.0], Predicción: 0.2500\n","Entrada: [1.0, 0.0], Predicción: 0.2500\n","Entrada: [1.0, 1.0], Predicción: 0.7500\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# Definir los datos de entrada y salida\n","# X = torch.tensor([[100], [135], [250]], dtype=torch.float32)\n","# y = torch.tensor([[30000],[60000],[15000]], dtype=torch.float32)\n","X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n","y = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)\n","\n","# Definir el modelo del perceptrón\n","class Perceptron(nn.Module):\n","    def __init__(self):\n","        super(Perceptron, self).__init__()\n","        self.fc = nn.Linear(2, 1)  # Capa lineal con 2 entradas y 1 salida\n","\n","    def forward(self, x):\n","        x = self.fc(x)  # Función de activación sigmoidal\n","        # x = torch.sigmoid(self.fc(x))  # Función de activación sigmoidal\n","        return x\n","\n","# Crear una instancia del modelo\n","perceptron = Perceptron()\n","\n","# Definir la función de pérdida y el optimizador\n","criterion = nn.MSELoss()  # Error cuadrático medio\n","#criterion = nn.BCEWithLogitsLoss()  # Error cuadrático medio\n","# criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(perceptron.parameters(), lr=0.1)  # Descenso de gradiente estocástico\n","\n","# Entrenar el perceptrón\n","num_epochs = 10000\n","for epoch in range(num_epochs):\n","    # Forward Pass\n","    outputs = perceptron(X)\n","    loss = criterion(outputs, y)\n","\n","    # Backward Pass y optimización\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 1000 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Evaluar el modelo entrenado\n","with torch.no_grad():\n","    test_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n","    predictions = perceptron(test_data)\n","    print(\"Predicciones finales:\")\n","    for i, pred in enumerate(predictions):\n","        print(f'Entrada: {test_data[i].tolist()}, Predicción: {pred.item():.4f}')\n"]}]}