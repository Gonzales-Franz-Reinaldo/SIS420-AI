{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOnY6s1mk+XoVNHHBXQBN/G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"stUHtyXwtUTc","executionInfo":{"status":"ok","timestamp":1714052334171,"user_tz":240,"elapsed":3,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["# used for manipulating directory paths\n","import os\n","\n","# Scientific and vector computation for python\n","import numpy as np\n","\n","# Plotting library\n","from matplotlib import pyplot\n","\n","# Optimization module in scipy\n","from scipy import optimize\n","\n","# will be used to load MATLAB mat datafile format\n","# from scipy.io import loadmat\n","\n","# library written for this exercise providing additional functions for assignment submission, and others\n","# import utils\n","\n","\n","# tells matplotlib to embed plots within the notebook\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCQdjXpNtha3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714052371306,"user_tz":240,"elapsed":37137,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"6d4418b5-7154-47df-cbdd-05e57253256e"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"GhiUwtKnule0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714052371306,"user_tz":240,"elapsed":5,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"807ee112-22d6-4a75-fa7e-537159800c5f"},"source":["!ls\n","%mkdir data\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive\tsample_data\n","data  gdrive  sample_data\n"]}]},{"cell_type":"code","metadata":{"id":"ZdNP-OaBtlmp","executionInfo":{"status":"ok","timestamp":1714052371306,"user_tz":240,"elapsed":3,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["import sys\n","\n","sys.path.insert(0, '/content/gdrive/MyDrive/Colab Notebooks/machine learning/datasets')\n","sys.path.insert(1, '/content/gdrive/MyDrive/Colab Notebooks/machine learning/03 redes neuronales')\n","\n","# from utils import displayData,"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1urWqmYvPE3","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":2879,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"d8ccf148-994c-425d-cdcc-9759f44de6ed"},"source":["import shutil\n","\n","shutil.copy('/content/gdrive/MyDrive/Colab Notebooks/machine learning/datasets/wine_preparado.csv', '/content/data')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/data/wine_preparado.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"iPKROwkOtpkn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714053824835,"user_tz":240,"elapsed":657,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"8b94cac3-551c-4842-a894-8b9d26038638"},"source":["#  datos de entrenamiento almacenados en los arreglos X, y\n","# data = np.loadtxt(\"/content/gdrive/MyDrive/Colab Notebooks/machine learning/datasets/wine_preparado.csv\", delimiter=',')\n","data = np.loadtxt(\"/content/data/wine_preparado.csv\", delimiter=',')\n","\n","# print(data)\n","X, y = data[:, 1:], data[:,0]\n","\n","y = np.array([int(e) for e in y])\n","print(y.shape)\n","y = np.squeeze(y)\n","\n","y[y == 1] = 0\n","y[y == 2] = 1\n","y[y == 3] = 2\n","\n","Xp= X[150:,:]\n","X = X[:150,:]\n","\n","yp = y[150:]\n","y = y[:150]\n","\n","\n","# print(npy)\n","# print(npy.shape)\n","# y = Y\n","# establecer el dígito cero en 0, en lugar del 10 asignado a este conjunto de datos\n","# Esto se hace debido a que el conjunto de datos se utilizó en MATLAB donde no hay índice 0\n","# m = y.size\n","print(X.shape)\n","print(y.shape)\n","print(Xp.shape)\n","print(yp.shape)\n","\n","\n","# print(X)\n","print(y)\n","print(yp)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["(178,)\n","(150, 13)\n","(150,)\n","(28, 13)\n","(28,)\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n","[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"]}]},{"cell_type":"code","metadata":{"id":"YN2IfP_5vz8v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":14,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"ed1b63c6-ce2a-47d0-982b-7e49c74d776d"},"source":["# Configurando parametros necesario\n","input_layer_size  = 13  # Entrada de 13 caracteristicas\n","hidden_layer_size = 10   # 10 unidades ocultas\n","num_labels = 3          # 3 etiquetas, de 0 a 2\n","\n","# carga los pesos en las variables Theta1 y Theta2\n","# weights = loadmat(os.path.join('/content/gdrive/MyDrive/Colab Notebooks/machine learning/data', 'ex4weights.mat'))\n","# weights = np.array()\n","pesos = {}\n","pesos['Theta1'] = np.random.rand(10, 14)\n","pesos['Theta2'] = np.random.rand(3, 11)\n","# print(pesos['Theta1'][:].shape)\n","# print(pesos['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][:].shape)\n","# print(weights['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][0])\n","# print(np.roll(weights['Theta1'][0], 1, axis=0))\n","# Theta1 tiene un tamaño de 25x401\n","# Theta2 tiene un tamañó de 10x26\n","# Theta1, Theta2 = weights['Theta1'], weights['Theta2']\n","Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n","# se intercambia la ultima columa con la primera de Theta2, por cuestiones de indices que utiliza MATLAB\n","# print(Theta2)\n","# print(np.roll(Theta2, 1, axis=0))\n","\n","# Theta2 = np.roll(Theta2, 1, axis=0)\n","\n","# Desenrollar parámetros\n","print(Theta1.ravel().shape)\n","print(Theta2.ravel().shape)\n","\n","nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n","print(nn_params.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(140,)\n","(33,)\n","(173,)\n"]}]},{"cell_type":"code","metadata":{"id":"IYkAveQh0e87","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":13,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["def sigmoid(z):\n","    \"\"\"\n","    Computes the sigmoid of z.\n","    \"\"\"\n","    return 1.0 / (1.0 + np.exp(-z))\n","\n","\n","def sigmoidGradient(z):\n","\n","    g = np.zeros(z.shape)\n","\n","    g = sigmoid(z) * (1 - sigmoid(z))\n","\n","    return g"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aevzq-rt0vKn","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":13,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["def nnCostFunction(nn_params,\n","                   input_layer_size,\n","                   hidden_layer_size,\n","                   num_labels,\n","                   X, y, lambda_= 0.0):\n","\n","    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n","    # for our 2 layer neural network\n","    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                        (hidden_layer_size, (input_layer_size + 1)))\n","\n","    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n","                        (num_labels, (hidden_layer_size + 1)))\n","\n","    m = y.size\n","\n","    J = 0\n","    Theta1_grad = np.zeros(Theta1.shape)\n","    Theta2_grad = np.zeros(Theta2.shape)\n","\n","    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    a2 = sigmoid(a1.dot(Theta1.T))\n","    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n","\n","    a3 = sigmoid(a2.dot(Theta2.T))\n","\n","    # print(\"-\"*20)\n","    # print(y.shape)\n","    # print(y.reshape(-1))\n","    # print(\"-\"*20)\n","    y_matrix = y.reshape(-1)\n","    # print(y.shape)\n","    y_matrix = np.eye(num_labels)[y_matrix]\n","    # print(y_matrix)\n","\n","    temp1 = Theta1\n","    temp2 = Theta2\n","\n","    # Agregar el termino de regularización\n","\n","    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n","\n","    J = (-1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix)) + reg_term\n","\n","    # Backpropogation\n","\n","    delta_3 = a3 - y_matrix\n","    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n","\n","    Delta1 = delta_2.T.dot(a1)\n","    Delta2 = delta_3.T.dot(a2)\n","\n","    # Agregar regularización al gradiente\n","\n","    Theta1_grad = (1 / m) * Delta1\n","    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n","\n","    Theta2_grad = (1 / m) * Delta2\n","    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n","\n","    # ===================== Alterntate solutions =====================\n","    # my_final_matrix = np.zeros(a3.shape)\n","    # for c in np.arange(num_labels):\n","    #    my_final_matrix[:, c] = (np.log(a3[:, c]) * (y == c)) + (np.log(1 - a3[:, c]) * (1 - (y == c)))\n","    #J = (-1 / m) * np.sum(my_final_matrix)\n","    # ================================================================\n","\n","    # ================================================================\n","    # Unroll gradients\n","    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n","\n","    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n","\n","    return J, grad"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4TjzE2h3BqL","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":12,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4cc70294-8e0a-4454-8ee2-d5da822b7686"},"source":["lambda_ = 0\n","J, _ = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n","print('Costo en parametros (cargado de ex4weights): %.6f ' % J)\n","print('El costo debe esta cercano a               : 0.287629')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Costo en parametros (cargado de ex4weights): 11.609228 \n","El costo debe esta cercano a               : 0.287629\n"]}]},{"cell_type":"code","metadata":{"id":"cT80ttRF-Rdv","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":11,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b889f53d-51c0-41d9-e0ff-72f6e2c41b51"},"source":["z = np.array([-1, -0.5, 0, 0.5, 1])\n","g = sigmoidGradient(z)\n","print('Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\\n  ')\n","print(g)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\n","  \n","[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"]}]},{"cell_type":"code","metadata":{"id":"EnKgJRZq-x3U","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n","    \"\"\"\n","    Randomly initialize the weights of a layer in a neural network.\n","\n","    Parameters\n","    ----------\n","    L_in : int\n","        Number of incomming connections.\n","\n","    L_out : int\n","        Number of outgoing connections.\n","\n","    epsilon_init : float, optional\n","        Range of values which the weight can take from a uniform\n","        distribution.\n","\n","    Returns\n","    -------\n","    W : array_like\n","        The weight initialiatized to random values.  Note that W should\n","        be set to a matrix of size(L_out, 1 + L_in) as\n","        the first column of W handles the \"bias\" terms.\"\"\"\n","\n","\n","    W = np.zeros((L_out, 1 + L_in))\n","    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n","\n","    return W"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"znk_8rO0-6fE","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b9a683b-1174-4635-e633-f26c03d371ac"},"source":["print('Inicialización de parámetros de redes neuronales...')\n","\n","initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n","initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n","\n","# Desenrrollr parametros\n","initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Inicialización de parámetros de redes neuronales...\n"]}]},{"cell_type":"code","metadata":{"id":"-ysYL_hX_D0k","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0ae7984-4221-4297-c093-bbd6bdecef90"},"source":["#  After you have completed the assignment, change the maxiter to a larger\n","#  value to see how more training helps.\n","options= {'maxiter': 1000}\n","\n","#  You should also try different values of lambda\n","lambda_ = 1\n","\n","# Create \"short hand\" for the cost function to be minimized\n","costFunction = lambda p: nnCostFunction(p, input_layer_size,\n","                                        hidden_layer_size,\n","                                        num_labels, X, y, lambda_)\n","\n","# Now, costFunction is a function that takes in only one argument\n","# (the neural network parameters)\n","res = optimize.minimize(costFunction,\n","                        initial_nn_params,\n","                        jac=True,\n","                        method='TNC',\n","                        options=options)\n","\n","# get the solution of the optimization\n","nn_params = res.x\n","\n","# Obtain Theta1 and Theta2 back from nn_params\n","Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                    (hidden_layer_size, (input_layer_size + 1)))\n","\n","Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n","                    (num_labels, (hidden_layer_size + 1)))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-2f5ec00f0be7>:15: OptimizeWarning: Unknown solver options: maxiter\n","  res = optimize.minimize(costFunction,\n","<ipython-input-8-fcf1f7fde265>:5: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n"]}]},{"cell_type":"code","metadata":{"id":"XDnQrQM4_0Ct","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":9,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["def predict(Theta1, Theta2, X):\n","    \"\"\"\n","    Predict the label of an input given a trained neural network\n","    Outputs the predicted label of X given the trained weights of a neural\n","    network(Theta1, Theta2)\n","    \"\"\"\n","    # Useful values\n","    m = X.shape[0]\n","    num_labels = Theta2.shape[0]\n","\n","    # You need to return the following variables correctly\n","    p = np.zeros(m)\n","    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n","    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n","    p = np.argmax(h2, axis=1)\n","    return p"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxMinI1Y_6AG","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":9,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a129f5b-574a-468a-eae5-dee890bd06e6"},"source":["pred = predict(Theta1, Theta2, X[:,:])\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == y[:]) * 100))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n","Training Set Accuracy: 98.666667\n"]}]},{"cell_type":"code","metadata":{"id":"1Qrmea3i_hip","executionInfo":{"status":"ok","timestamp":1714052374183,"user_tz":240,"elapsed":8,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aeae320f-f8da-4288-8e9e-f7e9ad65133a"},"source":["pred = predict(Theta1, Theta2, Xp[:,:])\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == yp[:]) * 100))\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","Training Set Accuracy: 100.000000\n"]}]}]}