{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"pytorch_ann_02.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"536fd69ec22545aa90123acb2e7ffbbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7c070424b7064582a8d7290622af3ca4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_350a20acfc7b4e0ea8c866524b9b45b6","IPY_MODEL_b9db973debdf4007ada8a97a1672cca1"]}},"7c070424b7064582a8d7290622af3ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"350a20acfc7b4e0ea8c866524b9b45b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_39c9f026387b47d9934fe36ba45ffd5e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":561753746,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":561753746,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5f26be1e4ff403ea54c0c4baf841578"}},"b9db973debdf4007ada8a97a1672cca1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60aa7c4bdb724fd3ad7b3f77ffa9c9db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 561754112/? [00:36&lt;00:00, 15493724.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_886a3671c7d44826b6472936dd210bfe"}},"39c9f026387b47d9934fe36ba45ffd5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b5f26be1e4ff403ea54c0c4baf841578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60aa7c4bdb724fd3ad7b3f77ffa9c9db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"886a3671c7d44826b6472936dd210bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"T2HWIl36XlPi"},"source":["# Redes Neuronales con Pytorch\n","\n","## Introduction\n","\n","En este ejercicio se implementa una red neuronal para reconocimiento de digitos utilizando pytorch.\n","\n","Antes de empezar la ejecución de las partes de codigo correspondienters a los ejercicios, se requiere importar todas las librerias necesarias."]},{"cell_type":"code","metadata":{"id":"RrkbuyYDXlPk","executionInfo":{"status":"ok","timestamp":1627176649753,"user_tz":240,"elapsed":2894,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","# Libreria para graficos\n","from matplotlib import pyplot as plt\n","\n","\n","import torch\n","import torchvision # torch package for vision related things\n","import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n","import torchvision.datasets as datasets  # Standard datasets\n","import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n","from torch import optim  # For optimizers like SGD, Adam, etc.\n","from torch import nn  # All neural network modules\n","from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n","from tqdm import tqdm  # For nice progress bar!\n","\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"hA63y9BgDGi-","executionInfo":{"status":"ok","timestamp":1627176649753,"user_tz":240,"elapsed":9,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["# Here we create our simple neural network. For more details here we are subclassing and\n","# inheriting from nn.Module, this is the most general way to create your networks and\n","# allows for more flexibility. I encourage you to also check out nn.Sequential which\n","# would be easier to use in this scenario but I wanted to show you something that\n","# \"always\" works.\n","class NNEMNIST(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(NNEMNIST, self).__init__()\n","        # Our first linear layer take input_size, in this case 784 nodes to 50\n","        # and our second linear layer takes 50 to the num_classes we have, in\n","        # this case 10.\n","        self.fc1 = nn.Linear(input_size, 300)\n","        # self.fc2 = nn.Linear(800, 150)\n","        self.fc2 = nn.Linear(300, num_classes)\n","\n","        # self.fc1 = nn.Linear(input_size, 47)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x here is the mnist images and we run it through fc1, fc2 that we created above.\n","        we also add a ReLU activation function in between and for that (since it has no parameters)\n","        I recommend using nn.functional (F)\n","        \"\"\"\n","        x = self.fc1(x)\n","        x = torch.relu(x)\n","        # x = F.sigmoid(self.fc1(x))\n","        x = self.fc2(x)\n","        # x = torch.sigmoid(x)\n","        # x = self.fc3(x)\n","        return x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COAUlsr8DLfF","executionInfo":{"status":"ok","timestamp":1627176649753,"user_tz":240,"elapsed":8,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"a0e86d6b-46f0-4de5-df2b-b5ed11236bdf"},"source":["# Set device cuda for GPU if it's available otherwise run on the CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Hyperparameters of our neural network which depends on the dataset, and\n","# also just experimenting to see what works well (learning rate for example).\n","input_size = 784\n","num_classes = 47\n","learning_rate = 0.001\n","batch_size = 500000\n","num_epochs = 5"],"execution_count":3,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192,"referenced_widgets":["536fd69ec22545aa90123acb2e7ffbbc","7c070424b7064582a8d7290622af3ca4","350a20acfc7b4e0ea8c866524b9b45b6","b9db973debdf4007ada8a97a1672cca1","39c9f026387b47d9934fe36ba45ffd5e","b5f26be1e4ff403ea54c0c4baf841578","60aa7c4bdb724fd3ad7b3f77ffa9c9db","886a3671c7d44826b6472936dd210bfe"]},"id":"10BjWiz3DYmW","executionInfo":{"status":"ok","timestamp":1627176679211,"user_tz":240,"elapsed":29461,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"d1ac540e-398b-4b3b-f873-5fb447f08547"},"source":["# Load Training and Test data\n","train_dataset = datasets.EMNIST(root=\"dataset/\", split=\"bymerge\", train=True, transform=transforms.ToTensor(), download=True)\n","test_dataset = datasets.EMNIST(root=\"dataset/\", split=\"bymerge\", train=False, transform=transforms.ToTensor(), download=True)\n","print(len(train_dataset))\n","print(len(test_dataset))\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to dataset/EMNIST/raw/gzip.zip\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"536fd69ec22545aa90123acb2e7ffbbc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=561753746.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting dataset/EMNIST/raw/gzip.zip to dataset/EMNIST/raw\n","697932\n","116323\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1iqKIj9bA4ZWHmrqWSCTam_PRireJejs8"},"id":"ZuMzsKyfSi-B","executionInfo":{"status":"ok","timestamp":1627180875778,"user_tz":240,"elapsed":56430,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"9c2a8743-637d-47ea-e284-9b49734d97da"},"source":["for c in train_dataset:\n","  print(c)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"_MtcDzEqEqeO","executionInfo":{"status":"ok","timestamp":1627176686005,"user_tz":240,"elapsed":6796,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["# Initialize network\n","model = NNEMNIST(input_size=input_size, num_classes=num_classes).to(device)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOXxAOpEFiCT","executionInfo":{"status":"ok","timestamp":1627176686007,"user_tz":240,"elapsed":9,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNVVsm2uXlPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627177118786,"user_tz":240,"elapsed":432788,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"8b8d1b36-42e8-42be-8a53-370d6b628ea6"},"source":["# Train Network\n","for epoch in range(num_epochs):\n","    train_loss, train_acc = [], []\n","\n","    # bar = tqdm(dataloader['train'])\n","    bar = tqdm(train_loader)\n","    for batch_idx, (data, targets) in enumerate(bar):\n","    # for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n","    # for batch_idx, (data, targets) in enumerate(train_loader):\n","\n","        # data, targets = batch.data, batch.targets\n","        # data, targets = data.to(device), targets.to(device)\n","\n","        # Get data to cuda if possible\n","        data = data.to(device=device)\n","        targets = targets.to(device=device)\n","        \n","        # print(data.shape)\n","        # Get to correct shape\n","        data = data.reshape(data.shape[0], -1)\n","        # print(data.shape)\n","        # print(\"-\"*30)\n","        # forward\n","        scores = model(data)\n","        print(scores.shape)\n","        print(targets.shape)\n","        loss = criterion(scores, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent or adam step\n","        optimizer.step()\n","        train_loss.append(loss.item())\n","        acc = (targets == torch.argmax(scores, axis=1)).sum().item() / len(targets)\n","        train_acc.append(acc)\n","        bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["loss 3.84292 acc 0.02511:  50%|█████     | 1/2 [01:03<01:03, 63.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([500000, 47])\n","torch.Size([500000])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.78205 acc 0.08336: 100%|██████████| 2/2 [01:28<00:00, 44.20s/it]\n","  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([197932, 47])\n","torch.Size([197932])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.60705 acc 0.17221:  50%|█████     | 1/2 [01:02<01:02, 62.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([500000, 47])\n","torch.Size([500000])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.54939 acc 0.18964: 100%|██████████| 2/2 [01:26<00:00, 43.15s/it]\n","  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([197932, 47])\n","torch.Size([197932])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.37952 acc 0.24882:  50%|█████     | 1/2 [01:01<01:01, 61.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([500000, 47])\n","torch.Size([500000])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.32848 acc 0.26669: 100%|██████████| 2/2 [01:25<00:00, 42.83s/it]\n","  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([197932, 47])\n","torch.Size([197932])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.18711 acc 0.31191:  50%|█████     | 1/2 [01:01<01:01, 61.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([500000, 47])\n","torch.Size([500000])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.14526 acc 0.32673: 100%|██████████| 2/2 [01:26<00:00, 43.10s/it]\n","  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([197932, 47])\n","torch.Size([197932])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 3.02321 acc 0.37711:  50%|█████     | 1/2 [01:02<01:02, 62.00s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([500000, 47])\n","torch.Size([500000])\n"],"name":"stdout"},{"output_type":"stream","text":["loss 2.98402 acc 0.39299: 100%|██████████| 2/2 [01:26<00:00, 43.09s/it]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([197932, 47])\n","torch.Size([197932])\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zfpwc1XSGbYs","executionInfo":{"status":"ok","timestamp":1627177217070,"user_tz":240,"elapsed":98288,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"374f28df-4753-42c6-e1a4-f6fd373697a4"},"source":["# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    predicciones = []\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","            x = x.reshape(x.shape[0], -1)\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            predicciones.append(predictions)\n","\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","    model.train()\n","    return num_correct/num_samples, predicciones\n","\n","p_train, pred_train  = check_accuracy(train_loader, model)\n","p_test, pred_test  = check_accuracy(test_loader, model)\n","\n","print(f\"Accuracy on training set: {p_train*100:.2f}\")\n","print(f\"Accuracy on test set: {p_test*100:.2f}\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 42.60\n","Accuracy on test set: 42.48\n"],"name":"stdout"}]}]}