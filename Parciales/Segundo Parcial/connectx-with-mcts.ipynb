{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Install kaggle-environments"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-01T22:11:47.723970Z","iopub.status.busy":"2022-06-01T22:11:47.723658Z","iopub.status.idle":"2022-06-01T22:12:04.424294Z","shell.execute_reply":"2022-06-01T22:12:04.423468Z","shell.execute_reply.started":"2022-06-01T22:11:47.723914Z"},"trusted":true},"outputs":[],"source":["# 1. Enable Internet in the Kernel (Settings side pane)\n","\n","# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n","#!curl -X PURGE https://pypi.org/simple/kaggle-environments\n","\n","# ConnectX environment was defined in v0.1.6\n","#!pip install 'kaggle-environments>=0.1.6'"]},{"cell_type":"markdown","metadata":{},"source":["# Create ConnectX Environment"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-06-01T22:12:04.428886Z","iopub.status.busy":"2022-06-01T22:12:04.428580Z","iopub.status.idle":"2022-06-01T22:12:04.650852Z","shell.execute_reply":"2022-06-01T22:12:04.650110Z","shell.execute_reply.started":"2022-06-01T22:12:04.428822Z"},"trusted":true},"outputs":[],"source":["# from kaggle_environments import evaluate, make, utils\n","# import numpy as np\n","# import time\n","\n","# env = make(\"connectx\", debug=True)\n","# env.render()"]},{"cell_type":"markdown","metadata":{},"source":["# Mi Codigo"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:12:04.653310Z","iopub.status.busy":"2022-06-01T22:12:04.652834Z","iopub.status.idle":"2022-06-01T22:12:04.660936Z","shell.execute_reply":"2022-06-01T22:12:04.660220Z","shell.execute_reply.started":"2022-06-01T22:12:04.653258Z"},"trusted":true},"outputs":[],"source":["from abc import abstractmethod\n","\n","class IGame:\n","\n","    @abstractmethod\n","    def is_game_over(board, inarow):\n","        pass\n","\n","    @abstractmethod\n","    def change_turn(player):\n","        pass\n","\n","    @abstractmethod\n","    def get_open_cols(board):\n","        pass\n","\n","    @abstractmethod\n","    def make_move(board, col, player):\n","        pass\n","\n","    @abstractmethod\n","    def get_turn(board):\n","        pass\n","\n","    @abstractmethod\n","    def print_board(board):\n","        pass"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:12:04.663394Z","iopub.status.busy":"2022-06-01T22:12:04.662885Z","iopub.status.idle":"2022-06-01T22:12:04.698431Z","shell.execute_reply":"2022-06-01T22:12:04.697494Z","shell.execute_reply.started":"2022-06-01T22:12:04.663183Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from functools import lru_cache\n","\n","class Connectx():\n","    def __init__(self, inarow, rows, cols):\n","        self.cols = cols\n","        self.rows = rows\n","        self.inarow = inarow\n","        \n","\n","    def change_turn(self, player): \n","        if player == '1':\n","            return '2'\n","        else:\n","            return '1'\n","\n","\n","    def get_open_cols(self, board):\n","        # board is serialized\n","        return [i for i in range(self.cols) if board[i] == '0']\n","\n","    def make_move(self, board, col, player):\n","\n","        entire_col = [board[i*self.cols + col] for i in range(self.rows)]\n","        for i, cell in enumerate(reversed(entire_col)):\n","            if cell == '0':\n","                board = board[:(self.rows-i-1)*self.cols + col] + player + board[(self.rows-i-1)*self.cols+col+1:]\n","                break\n","        return board\n","\n","    def get_turn(self, board):\n","        # assuming that '1' always starts playing\n","        ones = board.count('1')\n","        twos = board.count('2')\n","        return '1' if ones == twos else '2'\n","\n","    @lru_cache(maxsize=2048)\n","    def is_game_over(self, board, inarow):\n","        '''\n","        return the winner or '0' if there is no winner yet\n","        '''\n","        board2d = self.deserialize_board(board)\n","        \n","        # rows\n","        for i in range(self.rows):\n","            previous = ''\n","            count = 1\n","            for j in range(self.cols):\n","                current = board[i*self.cols + j]\n","                if previous != '0' and previous == current:\n","                    count += 1\n","                else:\n","                    count = 1\n","                if count == inarow:\n","                    return current\n","                previous = current\n","        \n","        # columns\n","        for i in range(self.cols):\n","            previous = ''\n","            count = 1\n","            for j in range(self.rows):\n","                current = board[j*self.cols + i]\n","                if previous != '0' and previous == current:\n","                    count += 1\n","                else:\n","                    count = 1\n","                if count == inarow:\n","                    return current\n","                previous = current\n","        \n","        # positive diagonal\n","        for row in range(self.rows-(inarow-1)):\n","            for col in range(self.cols-(inarow-1)):\n","                window = list(board2d[range(row, row+inarow), range(col, col+inarow)])\n","                \n","                if window.count('1') == inarow:\n","                    return '1'\n","                elif window.count('2') == inarow:\n","                    return '2'\n","\n","        # negative diagonal\n","        for row in range(inarow-1, self.rows):\n","            for col in range(self.cols-(inarow-1)):\n","                window = list(board2d[range(row, row-inarow, -1), range(col, col+inarow)])\n","                if window.count('1') == inarow:\n","                    return '1'\n","                elif window.count('2') == inarow:\n","                    return '2'\n","        return '0' if board.count('0') != 0 else 'draw'\n","\n","    def print_board(self, board):\n","        for i in range(self.rows):\n","            print('|', end='')\n","            for j in range(self.cols):\n","                print(board[i*self.cols + j], end='|')\n","            print()\n","        print(board)\n","    \n","    def serialize_board(self, board):\n","        return ''.join([str(cell) for row in board for cell in row])\n","\n","    def deserialize_board(self, board: str):\n","        return np.frombuffer(board.encode(), dtype=np.int8).reshape((self.rows, self.cols))\n","    \n","    def get_inputs(self, board, turn):\n","        board2d = self.deserialize_board(board)\n","        x1 = np.where(board2d == b'2', 1, 0)\n","        x2 = np.where(board2d == b'1', 1, 0)\n","        if turn == '2':\n","            x3 = np.ones((self.rows, self.cols))\n","        else:\n","            x3 = np.zeros((self.rows, self.cols))\n","        a = np.expand_dims(np.array([x1, x2, x3]), axis=0)\n","        return a"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:12:04.701994Z","iopub.status.busy":"2022-06-01T22:12:04.701674Z","iopub.status.idle":"2022-06-01T22:12:04.744088Z","shell.execute_reply":"2022-06-01T22:12:04.743235Z","shell.execute_reply.started":"2022-06-01T22:12:04.701947Z"},"trusted":true},"outputs":[],"source":["import time\n","from functools import lru_cache\n","\n","class MCTS:\n","\n","    def __init__(self, game: IGame = None, model=None):\n","        self.explored = set()\n","        self.nodes_parameters = {} # fen: (N, V) N--> times visited, V-->value\n","        # self.UCT = {} # fen: UPC (upper confidence tree)\n","        self.C = 3 # aprox sqrt(2)\n","        self.game = game\n","        self.probabilities = {}\n","        self.model = model\n","\n","    def get_value(self, result: str, player):\n","        if result == '1':\n","            return 1 if player == '1' else -1\n","\n","        elif result == '2':\n","            return -1 if player == '1' else 1 \n","        else:\n","            return 0\n","        \n","    @lru_cache(maxsize=2048)\n","    def search(self, s):\n","        result = self.game.is_game_over(s, self.game.inarow)\n","        if result != '0':\n","            v = self.get_value(result, self.game.get_turn(s)) \n","            if s not in self.nodes_parameters:\n","                self.nodes_parameters[s] = np.array((1, v))\n","            else:\n","                self.nodes_parameters[s][0] += 1\n","            return -v, 1\n","\n","        childs = self.game.get_open_cols(s)\n","\n","        if s in self.explored:\n","        # choose which node is going to be expanded\n","            best_uct = float('-inf')\n","            best_child = None\n","            turn = self.game.get_turn(s)\n","            # best_w = 0\n","            n_p = self.nodes_parameters[s][0] # parent's n\n","            for a in childs:\n","                s_child = self.game.make_move(s, a, turn)\n","                n, w = self.nodes_parameters[s_child]\n","                p = self.probabilities[s_child]    \n","                child_uct = self.get_UCT(n, w, n_p, p)\n","                if child_uct > best_uct:\n","                    best_uct = child_uct\n","                    best_child = a\n","            s_aux = self.game.make_move(s, best_child, self.game.get_turn(s))\n","            sum_v, sum_n = self.search(s_aux)\n","            # propagate the results\n","            self.nodes_parameters[s_aux][0] += sum_n\n","            self.nodes_parameters[s_aux][1] += sum_v\n","\n","        \n","        else:\n","            turn = self.game.get_turn(s)\n","            if len(self.explored) == 0:\n","                probs, v = self.model.predict(self.game.get_inputs(s, turn))\n","                self.add_probs(s, probs)\n","            self.explored.add(s)\n","            sum_v = 0\n","            sum_n = 0\n","            for a in childs:\n","                s_child = self.game.make_move(s, a, turn)\n","                if s_child not in self.nodes_parameters:\n","                    # v = self.simulate(s_child, turn, turn)\n","                    probs, v = self.model.predict(self.game.get_inputs(s_child, turn))\n","                    self.add_probs(s_child, probs)\n","                    # print(probs.shape, v.shape, v)\n","                    self.nodes_parameters[s_child] = np.array((1, v.squeeze()))\n","                    sum_v += v\n","                    sum_n += 1\n","                \n","            self.nodes_parameters[s][0] += sum_n\n","            self.nodes_parameters[s][1] += sum_v\n","\n","        return -sum_v, sum_n\n","    \n","    def add_probs(self, state, probs):\n","        open_cols = self.game.get_open_cols(state)\n","        not_open_cols = [i for i in range(self.game.cols) if i not in open_cols]\n","        probs = probs.reshape((self.game.cols,))\n","        probs[not_open_cols] = 0\n","        for a, prob in enumerate(np.ravel(probs)):\n","            child_state = self.game.make_move(state, a, self.game.get_turn(state))\n","            self.probabilities[child_state] = prob\n","\n","    \n","\n","    def simulate(self, s, color_playing, turn):\n","        result = self.game.is_game_over(s, self.game.inarow)\n","        while result == '0': \n","            move = np.random.choice(self.game.get_open_cols(s))\n","            s = self.game.make_move(s, move, turn)\n","            result = self.game.is_game_over(s, self.game.inarow)\n","            turn = self.game.change_turn(turn)\n","        return self.get_value(result, color_playing)\n","\n","\n","    def get_UCT(self, n, w, n_p, p):\n","        # return w/n + self.C * np.sqrt(n_p) / (1 + n)\n","        return w/n + self.C * p * np.sqrt(np.log(n_p) / (n + 1))\n","    \n","    def get_pi(self, state, tau=1):\n","        pi = []\n","        turn = self.game.get_turn(state)\n","        open_cols =  self.game.get_open_cols(state)\n","        for a in range(self.game.cols):\n","            if a not in open_cols:\n","                pi.append(0)\n","            else:\n","                s_child = self.game.make_move(state, a, turn)\n","                pi.append(self.nodes_parameters[s_child][0])\n","        pi = np.power(pi, tau) \n","        pi_sum = np.sum(pi)\n","        return np.divide(pi, pi_sum)\n","    \n","    def iterate(self, s, n_iters=None, time_limit=None):\n","        self.nodes_parameters[s] = np.array((1, 0))\n","        if time_limit is not None:\n","            end_time = time.time() + time_limit\n","            while time.time() < end_time:\n","                v, n = self.search(s)\n","                self.nodes_parameters[s][0] += n\n","                self.nodes_parameters[s][1] += v\n","        else:            \n","            for _ in range(n_iters):\n","                v, n = self.search(s)\n","                self.nodes_parameters[s][0] += n\n","                self.nodes_parameters[s][1] += v\n","\n","    def best_move(self, board, turn, n_iters=None, time_limit=None):\n","        self.iterate(board, n_iters=n_iters, time_limit=time_limit)\n","        max_n = 0\n","        best_move = 3 # por ejemplo 3\n","        for a in self.game.get_open_cols(board):\n","            c_aux = self.game.make_move(board, a, turn)\n","            if self.game.is_game_over(c_aux, self.game.inarow) != '0':\n","                return a\n","            current_n = self.nodes_parameters[c_aux][0]\n","            if current_n > max_n:\n","                max_n = current_n\n","                best_move = a\n","            # print(f'N: {self.nodes_parameters[c_aux][0]} , V: {self.nodes_parameters[c_aux][1]}')\n","            # self.game.print_board(c_aux)\n","        return best_move\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Neural Network"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:12:04.746370Z","iopub.status.busy":"2022-06-01T22:12:04.745881Z","iopub.status.idle":"2022-06-01T22:12:10.446793Z","shell.execute_reply":"2022-06-01T22:12:10.446056Z","shell.execute_reply.started":"2022-06-01T22:12:04.746314Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-22 21:41:39.762190: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-04-22 21:41:39.789241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-22 21:41:40.204507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-04-22 21:41:40.649277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-04-22 21:41:40.649437: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["from tensorflow.keras.layers import Input, Conv2D, Dense, BatchNormalization, ReLU, Add, Flatten\n","from tensorflow.keras import Model\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","\n","physical_devices = tf.config.list_physical_devices('GPU')\n","# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","if len(physical_devices) > 0:\n","    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n","    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n","\n","class NeuralNetwok():\n","    \n","\n","    def __init__(self, rows, cols, l_rate):\n","        self.rows = rows\n","        self.cols = cols\n","        self.l_rate = l_rate\n","        self.N_BLOCKS = 2\n","        self.KERNEL_SIZE = (3, 3) # the stride will be 1 (the default used by keras)\n","        self.FILTERS = 128\n","        self.model = self.create_model(rows, cols, self.N_BLOCKS)\n","        \n","    \n","    def create_model(self, rows, cols, n_blocks):\n","        # input of the neural network\n","        # 3 channels: one board with the position of th X's,\n","        # other with the positions of the O's and the last, all 1 if X plays or all 0 if O plays\n","        input_layer = Input(shape=(3, rows, cols))\n","        \n","        # body (residual blocks)\n","        x = self.add_convolutional_layer(input_layer, self.FILTERS, self.KERNEL_SIZE)\n","        for _ in range(n_blocks):\n","            x = self.add_residual_block(x)\n","            \n","        # add policy head\n","        policy_head_output = self.add_policy_head(x)\n","        \n","        # add value head\n","        value_head_output = self.add_value_head(x)\n","        \n","        model = Model(inputs=input_layer, outputs=[policy_head_output, value_head_output])\n","        # model.compile(\n","        #     optimizer = Adam(self.l_rate),\n","        #     loss = ['categorical_crossentropy','mean_squared_error']\n","        # )\n","        return model\n","        \n","    def add_residual_block(self, x):\n","        # first convolutional layer\n","        y = self.add_convolutional_layer(x, self.FILTERS, self.KERNEL_SIZE)\n","        \n","        # second convolutional layer\n","        y = Conv2D(self.FILTERS, self.KERNEL_SIZE, data_format='channels_first', padding='same')(y)\n","        y = BatchNormalization()(y)\n","        y = Add()([x, y])\n","        y = ReLU()(y)\n","        return y\n","    \n","    def add_convolutional_layer(self, x, filters, kernel_size):\n","        y = Conv2D(filters, kernel_size, data_format='channels_first', padding='same')(x)\n","        # padding has to be 'same' in order to keep the dimensions right\n","        # data_format=channels_first corresponds to inputs with shape (batch_size, channels, height, width).\n","        y = BatchNormalization()(y)\n","        y = ReLU()(y)\n","        return y\n","    \n","    def add_policy_head(self, x):\n","        y = self.add_convolutional_layer(x, 2, (1, 1))\n","        y = Flatten()(y)\n","        y = Dense(self.cols, activation='softmax')(y) # TODO: podria llegar a hacerse de tamaño rows*cols, ni idea\n","        # move logit probabilities\n","        return y\n","    \n","    def add_value_head(self, x):\n","        y = self.add_convolutional_layer(x, 1, (1, 1))\n","        y = Flatten()(y)\n","        y = Dense(128)(y)\n","        y = ReLU()(y)\n","        y = Dense(1, activation='tanh')(y)\n","        return y\n","    \n","    def predict(self, x):\n","        return self.model.predict(x, verbose=0)\n","    \n","    def train(self, x, y):\n","        self.model.compile(\n","            optimizer = Adam(self.l_rate),\n","            loss = ['categorical_crossentropy','mean_squared_error']\n","        )\n","        with tf.device('/gpu:0'):\n","            history = self.model.fit(epochs=25,\n","                                 batch_size=32,\n","                                 x=x, \n","                                 y=y,\n","                                 verbose=1)\n","        \n","            \n","    def save(self, file_name):\n","        self.model.save(file_name)\n","\n","    @staticmethod\n","    def load_network(file_name, lr=0.01):\n","        model = load_model(file_name)\n","        nn = NeuralNetwok(6, 7, lr)\n","        nn.model = model\n","        return nn"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:29:30.684034Z","iopub.status.busy":"2022-06-01T22:29:30.683651Z","iopub.status.idle":"2022-06-01T22:29:30.742801Z","shell.execute_reply":"2022-06-01T22:29:30.742111Z","shell.execute_reply.started":"2022-06-01T22:29:30.683970Z"},"trusted":true},"outputs":[],"source":["from threading import Thread, Barrier\n","\n","class Player:\n","\n","    def __init__(self, mcts):\n","        self.mcts = mcts\n","\n","    def play(self, iterations, num_games, starting_iteration=0, n_threads=4):\n","        for i in range(starting_iteration, iterations):\n","            neural_network = self.mcts.model\n","            neural_network.save(f'model_iter_{i}.h5')\n","\n","            # initialize the arrays\n","            # x, pi_s, results = self.generate_examples() # TODO: usar el metodo paralelo\n","            examples = self.generate_examples_parallel(f'model_iter_{i}.h5', n_threads)\n","            x, pi_s, results = examples[0]\n","            for example in examples[1:]:\n","                    x = np.vstack((x, example[0]))\n","                    print(example[1].shape)\n","                    pi_s = np.vstack((pi_s, example[1]))\n","                    results = np.concatenate((results, example[2]))\n","            print(pi_s.shape)\n","            for j in range(num_games - 1):\n","                print(f'generating data for iteration {i} and game {j}')\n","                # states, pi, result = self.generate_examples()\n","                # x = np.vstack((x, states))\n","                # print(pi.shape)\n","                # pi_s = np.vstack((pi_s, pi))\n","                # results = np.concatenate((results, result))\n","                examples = self.generate_examples_parallel(f'model_iter_{i}.h5', n_threads)\n","                for example in examples:\n","                    x = np.vstack((x, example[0]))\n","                    print(example[1].shape)\n","                    pi_s = np.vstack((pi_s, example[1]))\n","                    results = np.concatenate((results, example[2]))\n","\n","            y = (pi_s, results.reshape(-1, 1))\n","            print(x.shape)\n","            print(y[0].shape)\n","            print(y[1].shape)\n","            neural_network.train(x, y)\n","\n","            old_network = NeuralNetwok.load_network(f'model_iter_{i}.h5')\n","            neural_network.save(f'model_iter_{i}_trained.h5')\n","            win_rate = self.simulate_games_parallel(f'model_iter_{i}.h5', f'model_iter_{i}_trained.h5', games_per_thread=10, n_threads=n_threads)\n","            # win_rate = self.simulate_games(old_network, 25) # TODO: usar variable global\n","            print(f'winrate of the {i}th iteration: {win_rate}')\n","            # if the trained network is not much better than the previous one, then the previous one remains as the current network\n","            if win_rate < 0.55:\n","                self.mcts.model = old_network\n","\n","\n","    def generate_examples(self):\n","        states = []\n","        pi_s = []\n","        board = '0' * (self.mcts.game.rows * self.mcts.game.cols)\n","        result = '0'\n","        current_turn = '1'\n","        while result == '0':\n","            move = self.mcts.best_move(board, current_turn, n_iters=25)\n","            pi = self.mcts.get_pi(board)\n","            print(f'pi: {pi}')\n","            pi_s.append(pi)\n","            board = self.mcts.game.make_move(board, move, current_turn)\n","            states.append(self.mcts.game.get_inputs(board, current_turn)[0])\n","            result = self.mcts.game.is_game_over(board, self.mcts.game.inarow)\n","            current_turn = self.mcts.game.change_turn(current_turn)\n","        total_moves = len(states)\n","        results = np.ones(total_moves)\n","        self.mcts.game.print_board(board)\n","        if result == '1':\n","            results[1::2] = -1\n","        elif result == '2':\n","            results[::2] = -1\n","        else:\n","            results = np.zeros(total_moves)\n","\n","        return (states, np.array(pi_s), results)\n","\n","    def generate_examples_parallel(self, path_current_model, n_threads):\n","        barrier = Barrier(n_threads + 1)\n","        examples = [0] * n_threads\n","        rows = self.mcts.game.rows\n","        cols = self.mcts.game.cols\n","        inarow = self.mcts.game.inarow\n","        def generate(thread_id):\n","            model = NeuralNetwok.load_network(path_current_model)\n","            game = Connectx(inarow, rows, cols)\n","            mcts = MCTS(game, model)\n","            states = []\n","            pi_s = []\n","            board = '0' * (rows * cols)\n","            result = '0'\n","            current_turn = '1'\n","            while result == '0':\n","                move = mcts.best_move(board, current_turn, n_iters=25)\n","                pi = mcts.get_pi(board)\n","                pi_s.append(pi)\n","                board = game.make_move(board, move, current_turn)\n","                states.append(game.get_inputs(board, current_turn)[0])\n","                result = game.is_game_over(board, game.inarow)\n","                current_turn = game.change_turn(current_turn)\n","            total_moves = len(states)\n","            results = np.ones(total_moves)\n","            if result == '1':\n","                results[1::2] = -1\n","            elif result == '2':\n","                results[::2] = -1\n","            else:\n","                results = np.zeros(total_moves)\n","            examples[thread_id] = (states, np.array(pi_s), results)\n","            print(f'thread {thread_id} ended, result: {result}')\n","            barrier.wait()\n","\n","        for thread_id in range(n_threads):\n","            t = Thread(target=generate, args=[thread_id])\n","            t.start()\n","        barrier.wait()\n","        return examples\n","\n","    def simulate_games(self, old_network, num_games):\n","        old_mcts = MCTS()\n","        old_mcts.game = self.mcts.game\n","        old_mcts.model = old_network\n","        num_wins = 0\n","        for i in range(num_games):\n","            color_old_network = '1' if np.random.uniform() < 0.5 else '2'\n","            color_new_network = '2' if color_old_network == '1' else '1'\n","            result = self.play_one_game(old_mcts, color_old_network)\n","            if result == color_new_network:\n","                num_wins += 1\n","        return num_wins / num_games\n","\n","    def play_one_game(self, rival, rival_color):\n","        board = '0' * (self.mcts.game.rows * self.mcts.game.cols)\n","        result = '0'\n","        is_rival_turn = rival_color == '1'\n","        current_player_color = '2' if is_rival_turn else '1'\n","        while result == '0':\n","            if is_rival_turn:\n","                move = rival.best_move(board, rival_color, n_iters=33) # TODO: usar variables globales para n_iters\n","                board = self.mcts.game.make_move(board, move, rival_color)\n","            else:\n","                move = self.mcts.best_move(board, current_player_color, n_iters=33)\n","                board = self.mcts.game.make_move(board, move, current_player_color)\n","            is_rival_turn = not is_rival_turn\n","            result = self.mcts.game.is_game_over(board, self.mcts.game.inarow)\n","        return result\n","\n","    def simulate_games_parallel(self, old_network_path, current_network_path, games_per_thread, n_threads):\n","        barrier = Barrier(n_threads + 1)\n","        rows = self.mcts.game.rows\n","        cols = self.mcts.game.cols\n","        inarow = self.mcts.game.inarow\n","        game = self.mcts.game\n","        wins = [0] * n_threads\n","        def play_game(thread_id):\n","            old_network = NeuralNetwok.load_network(old_network_path)\n","            current_network = NeuralNetwok.load_network(current_network_path)\n","            for i in range(games_per_thread):\n","                old_mcts = MCTS(game, old_network)\n","                current_mcts = MCTS(game, current_network)\n","                board = '0' * (rows * cols)\n","                result = '0'\n","                color_old_network = '1' if np.random.uniform() < 0.5 else '2'\n","                is_old_net_turn = color_old_network == '1'\n","                current_player_color = '2' if is_old_net_turn else '1'\n","                while result == '0':\n","                    if is_old_net_turn:\n","                        move = old_mcts.best_move(board, color_old_network, n_iters=33) # TODO: usar variables globales para n_iters\n","                        board = game.make_move(board, move, color_old_network)\n","                    else:\n","                        move = current_mcts.best_move(board, current_player_color, n_iters=33)\n","                        board = game.make_move(board, move, current_player_color)\n","                    is_old_net_turn = not is_old_net_turn\n","                    result = game.is_game_over(board, inarow)\n","\n","                if result == current_player_color:\n","                    wins[thread_id] += 1\n","                game.print_board(board)\n","                print(f'result of game {i} in thread {thread_id}: {result}')\n","            barrier.wait()\n","\n","        for thread_id in range(n_threads):\n","            t = Thread(target=play_game, args=[thread_id])\n","            t.start()\n","        barrier.wait()\n","        print(wins)\n","        return sum(wins) / (games_per_thread * n_threads)"]},{"cell_type":"markdown","metadata":{},"source":["# Train the neural network"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:12:10.448577Z","iopub.status.busy":"2022-06-01T22:12:10.448267Z","iopub.status.idle":"2022-06-01T22:12:12.644173Z","shell.execute_reply":"2022-06-01T22:12:12.643441Z","shell.execute_reply.started":"2022-06-01T22:12:10.448527Z"},"trusted":true},"outputs":[],"source":["nn = NeuralNetwok(6, 7, 0.01)\n","#plot_model(nn.model, show_shapes=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:29:32.061142Z","iopub.status.busy":"2022-06-01T22:29:32.060787Z","iopub.status.idle":"2022-06-01T22:29:32.432657Z","shell.execute_reply":"2022-06-01T22:29:32.431801Z","shell.execute_reply.started":"2022-06-01T22:29:32.061091Z"},"trusted":true},"outputs":[],"source":["game = Connectx(4, 6, 7)\n","nn = NeuralNetwok(6, 7, 0.01)\n","mcts = MCTS(game, nn)\n","player = Player(mcts)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-06-01T22:29:32.726245Z","iopub.status.busy":"2022-06-01T22:29:32.725865Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/tmp/ipykernel_1618635/2772718001.py:79: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  self.nodes_parameters[s][1] += sum_v\n","/tmp/ipykernel_1618635/2772718001.py:134: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  self.nodes_parameters[s][1] += v\n"]},{"name":"stdout","output_type":"stream","text":["thread 3 ended, result: 1\n","thread 0 ended, result: 1\n","thread 2 ended, result: 1\n","thread 1 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(60, 7)\n","generating data for iteration 0 and game 0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 377 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f11cc7a6520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 377 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f11cc7a6520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["thread 1 ended, result: 1\n","thread 2 ended, result: 1\n","thread 0 ended, result: 1\n","thread 3 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","generating data for iteration 0 and game 1\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 377 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f11cc2b8680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 377 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f11cc2b8680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["thread 1 ended, result: 1\n","thread 2 ended, result: 1\n","thread 3 ended, result: 1\n","thread 0 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","generating data for iteration 0 and game 2\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stdout","output_type":"stream","text":["thread 2 ended, result: 1\n","thread 0 ended, result: 1\n","thread 1 ended, result: 1\n","thread 3 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","generating data for iteration 0 and game 3\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stdout","output_type":"stream","text":["thread 0 ended, result: 1\n","thread 2 ended, result: 1\n","thread 1 ended, result: 1\n","thread 3 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(300, 3, 6, 7)\n","(300, 7)\n","(300, 1)\n","Epoch 1/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0286\n","Epoch 2/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.4004\n","Epoch 3/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.2893\n","Epoch 4/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.2291\n","Epoch 5/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.1215\n","Epoch 6/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.1010\n","Epoch 7/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0723\n","Epoch 8/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.0387\n","Epoch 9/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9993\n","Epoch 10/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9999\n","Epoch 11/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9870\n","Epoch 12/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9704\n","Epoch 13/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9581\n","Epoch 14/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9554\n","Epoch 15/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9484\n","Epoch 16/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9429\n","Epoch 17/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9406\n","Epoch 18/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9427\n","Epoch 19/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9417\n","Epoch 20/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9337\n","Epoch 21/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9288\n","Epoch 22/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9208\n","Epoch 23/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9211\n","Epoch 24/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9234\n","Epoch 25/25\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9265\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 0 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 0 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 0 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 0 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 1 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 1 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 1 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 1 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 2 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 2 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 2 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 2 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 3 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 3 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 3 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 3 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 4 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 4 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 4 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 4 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 5 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 5 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 5 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 5 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 6 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 6 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 6 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 6 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 7 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 7 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 7 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 7 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 8 in thread 0: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 8 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 8 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 8 in thread 2: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 9 in thread 0: 1\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 9 in thread 1: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 9 in thread 3: 1\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|0|0|0|0|0|\n","|1|1|0|0|0|0|0|\n","|2|2|2|0|0|0|0|\n","|1|1|1|1|0|0|0|\n","220000011000002200000110000022200001111000\n","result of game 9 in thread 2: 1\n","[4, 6, 6, 8]\n","winrate of the 0th iteration: 0.6\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["thread 1 ended, result: 1\n","thread 0 ended, result: 1\n","thread 3 ended, result: 1\n","thread 2 ended, result: 1\n","(15, 7)\n","(15, 7)\n","(15, 7)\n","(60, 7)\n","generating data for iteration 1 and game 0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[11], line 30\u001b[0m, in \u001b[0;36mPlayer.play\u001b[0;34m(self, iterations, num_games, starting_iteration, n_threads)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerating data for iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and game \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# states, pi, result = self.generate_examples()\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# x = np.vstack((x, states))\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(pi.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pi_s = np.vstack((pi_s, pi))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# results = np.concatenate((results, result))\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_examples_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_iter_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((x, example[\u001b[38;5;241m0\u001b[39m]))\n","Cell \u001b[0;32mIn[11], line 118\u001b[0m, in \u001b[0;36mPlayer.generate_examples_parallel\u001b[0;34m(self, path_current_model, n_threads)\u001b[0m\n\u001b[1;32m    116\u001b[0m     t \u001b[38;5;241m=\u001b[39m Thread(target\u001b[38;5;241m=\u001b[39mgenerate, args\u001b[38;5;241m=\u001b[39m[thread_id])\n\u001b[1;32m    117\u001b[0m     t\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 118\u001b[0m \u001b[43mbarrier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m examples\n","File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:723\u001b[0m, in \u001b[0;36mBarrier.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_release()\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# We wait until someone releases us\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:758\u001b[0m, in \u001b[0;36mBarrier._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;66;03m#timed out.  Break the barrier\u001b[39;00m\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_break()\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenBarrierError\n","File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:390\u001b[0m, in \u001b[0;36mCondition.wait_for\u001b[0;34m(self, predicate, timeout)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m waittime \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    389\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaittime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     result \u001b[38;5;241m=\u001b[39m predicate()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["player.play(100, 5, n_threads=4)"]},{"cell_type":"markdown","metadata":{},"source":["# Create an Agent\n","\n","To create the submission, an agent function should be fully encapsulated (no external dependencies).  \n","\n","When your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T13:48:48.273499Z","iopub.status.busy":"2022-05-26T13:48:48.273012Z","iopub.status.idle":"2022-05-26T13:48:48.282956Z","shell.execute_reply":"2022-05-26T13:48:48.281937Z","shell.execute_reply.started":"2022-05-26T13:48:48.273443Z"},"trusted":true},"outputs":[],"source":["import functools\n","# This agent random chooses a non-empty column.\n","\n","def my_agent(observation, configuration):\n","    board = functools.reduce(lambda x, y: str(x) + str(y), observation.board)\n","    game = Connectx(configuration.inarow, configuration.rows, configuration.columns)\n","    mcts = MCTS(game, nn)\n","    turn = str(observation.mark)\n","    \n","#     print(turn, configuration.rows, configuration.columns)\n","#     print(board)\n","    game.print_board(board)\n","    move = mcts.best_move(board, turn, n_iters=40)\n","    for a in mcts.game.get_open_cols(board):\n","        c_aux = mcts.game.make_move(board, a, turn)\n","        print(f'N: {mcts.nodes_parameters[c_aux][0]} , V: {mcts.nodes_parameters[c_aux][1]}')\n","#     print(move)\n","    return move"]},{"cell_type":"markdown","metadata":{},"source":["# Test your Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T13:48:48.28511Z","iopub.status.busy":"2022-05-26T13:48:48.284587Z","iopub.status.idle":"2022-05-26T13:49:28.515452Z","shell.execute_reply":"2022-05-26T13:49:28.514634Z","shell.execute_reply.started":"2022-05-26T13:48:48.284913Z"},"trusted":true},"outputs":[],"source":["env.reset()\n","# Play as the first agent against default \"random\" agent.\n","env.run([\"negamax\", my_agent])\n","env.render(mode=\"ipython\", width=500, height=450)"]},{"cell_type":"markdown","metadata":{},"source":["# Debug/Train your Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T13:49:28.517868Z","iopub.status.busy":"2022-05-26T13:49:28.517332Z","iopub.status.idle":"2022-05-26T13:50:33.468712Z","shell.execute_reply":"2022-05-26T13:50:33.466873Z","shell.execute_reply.started":"2022-05-26T13:49:28.517665Z"},"trusted":true},"outputs":[],"source":["# Play as first position against random agent.\n","trainer = env.train([None, \"random\"])\n","\n","observation = trainer.reset()\n","\n","while not env.done:\n","    my_action = my_agent(observation, env.configuration)\n","    print(\"My Action\", my_action)\n","    observation, reward, done, info = trainer.step(my_action)\n","    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n","env.render()"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate your Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-20T21:27:33.205993Z","iopub.status.busy":"2022-04-20T21:27:33.205674Z","iopub.status.idle":"2022-04-20T21:47:17.80321Z","shell.execute_reply":"2022-04-20T21:47:17.801646Z","shell.execute_reply.started":"2022-04-20T21:27:33.205941Z"},"trusted":true},"outputs":[],"source":["def mean_reward(rewards):\n","    return sum(r[0] for r in rewards) / float(len(rewards))\n","\n","# Run multiple episodes to estimate its performance.\n","print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n","print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))"]},{"cell_type":"markdown","metadata":{},"source":["# Play your Agent\n","Click on any column to place a checker there (\"manually select action\")."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-03T17:06:22.740926Z","iopub.status.busy":"2022-05-03T17:06:22.740588Z","iopub.status.idle":"2022-05-03T17:06:31.408044Z","shell.execute_reply":"2022-05-03T17:06:31.407172Z","shell.execute_reply.started":"2022-05-03T17:06:22.740872Z"},"trusted":true},"outputs":[],"source":["# \"None\" represents which agent you'll manually play as (first or second player).\n","env.play([my_agent, None], width=500, height=450)"]},{"cell_type":"markdown","metadata":{},"source":["# Write Submission File\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-19T18:55:55.250318Z","iopub.status.busy":"2022-04-19T18:55:55.249739Z","iopub.status.idle":"2022-04-19T18:55:55.25931Z","shell.execute_reply":"2022-04-19T18:55:55.258129Z","shell.execute_reply.started":"2022-04-19T18:55:55.250264Z"},"trusted":true},"outputs":[],"source":["import inspect\n","import os\n","\n","def write_agent_to_file(function, file):\n","    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n","        f.write(inspect.getsource(function))\n","        print(function, \"written to\", file)\n","\n","write_agent_to_file(my_agent, \"submission.py\")"]},{"cell_type":"markdown","metadata":{},"source":["# Validate Submission\n","Play your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n","\n","Why validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-19T18:58:39.674956Z","iopub.status.busy":"2022-04-19T18:58:39.674545Z","iopub.status.idle":"2022-04-19T18:58:39.697888Z","shell.execute_reply":"2022-04-19T18:58:39.696281Z","shell.execute_reply.started":"2022-04-19T18:58:39.67489Z"},"trusted":true},"outputs":[],"source":["# Note: Stdout replacement is a temporary workaround.\n","import sys\n","out = sys.stdout\n","submission = utils.read_file(\"/kaggle/working/submission.py\")\n","agent = utils.get_last_callable(submission)\n","sys.stdout = out\n","\n","env = make(\"connectx\", debug=True)\n","env.run([agent, agent])\n","print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"]},{"cell_type":"markdown","metadata":{},"source":["# Submit to Competition\n","\n","1. Commit this kernel.\n","2. View the commited version.\n","3. Go to \"Data\" section and find submission.py file.\n","4. Click \"Submit to Competition\"\n","5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
