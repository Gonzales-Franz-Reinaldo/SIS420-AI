{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMER PARCIAL SIS420 \n",
    "\n",
    "# Regresión Logística Binari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacion del modelo de regresion logistica para realizar predicciones.\n",
    "\n",
    "En este ejercicio se implementa regresion logistica y se aplica a dos diferentes datasets.\n",
    "\n",
    "Nuestro objetuvo es predecir si una persona tiene o no el Cardiovascular.\n",
    "En el siguiente dataset `cardio_train` se encuentran todos los datos.\n",
    "\n",
    "Link del Dataset: https://www.kaggle.com/datasets/bhadaneeraj/cardio-vascular-disease-detection?select=cardio_train.csv\n",
    "\n",
    "Enlace del GitHub:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias\n",
    "\n",
    "# se utiliza para el manejo de rutas y directorios.\n",
    "import os\n",
    "\n",
    "# Calculo cientifico y vectorial para python\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Modulo de optimización de scipy\n",
    "from scipy import optimize\n",
    "\n",
    "#Para separa el Dataset 20% y 80% para diferentes pruebas\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Información del Dataset**\n",
    "\n",
    "\n",
    "Acerca del conjunto de datos\n",
    "\n",
    "Detección de enfermedades cardiovasculares\n",
    "\n",
    "Cita:\n",
    "\n",
    "Licencia: Desconocida\n",
    "\n",
    "Dominio: Público\n",
    "\n",
    "Propietario del conjunto de datos: Svetlana Ulianova\n",
    "\n",
    "Fecha de creación: 2019-01-20\n",
    "\n",
    "\n",
    "## Características:\n",
    "\n",
    "\n",
    "Edad | Característica de objetivo | Edad | int (días)\n",
    "\n",
    "Altura | Característica de objetivo | Altura | int (cm) |\n",
    "\n",
    "Peso | Característica de objetivo | Peso | flotador (kg) |\n",
    "\n",
    "Género | Característica de objetivo | Género | Código categórico |\n",
    "\n",
    "Presión arterial sistólica | Función de examen | ap_hi | int |\n",
    "\n",
    "Presión arterial diastólica | Función de examen | ap_lo | int |\n",
    "\n",
    "Colesterol | Función de examen | Colesterol | 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal |\n",
    "\n",
    "Glucosa | Función de examen | gluc | 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal |\n",
    "\n",
    "Fumar | Característica subjetiva | Humo | binario |\n",
    "\n",
    "Consumo de alcohol | Característica subjetiva | ALCO | binario |\n",
    "\n",
    "Actividad física | Característica subjetiva | Activo | binario |\n",
    "\n",
    "Presencia o ausencia de enfermedad cardiovascular | Variable objetivo | Cardio | binario |\n",
    "\n",
    "Todos los valores del conjunto de datos se recogieron en el momento del examen médico.\n",
    "\n",
    "\n",
    "## El enunciado del problema:\n",
    "\n",
    "Construir una aplicación para clasificar a los pacientes como sanos o que sufren de enfermedades cardiovasculares en función de los atributos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988</td>\n",
       "      <td>22469</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>69.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989</td>\n",
       "      <td>14648</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>71.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>21901</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>991</td>\n",
       "      <td>14549</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>85.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>992</td>\n",
       "      <td>23393</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69296</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69297</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69298</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69299</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69300</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69301 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "0        988  22469       1     155    69.0    130     80            2     2   \n",
       "1        989  14648       1     163    71.0    110     70            1     1   \n",
       "2        990  21901       1     165    70.0    120     80            1     1   \n",
       "3        991  14549       2     165    85.0    120     80            1     1   \n",
       "4        992  23393       1     155    62.0    120     80            1     1   \n",
       "...      ...    ...     ...     ...     ...    ...    ...          ...   ...   \n",
       "69296  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69297  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69298  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69299  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69300  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "0          0     0       1       0  \n",
       "1          0     0       1       1  \n",
       "2          0     0       1       0  \n",
       "3          1     1       1       0  \n",
       "4          0     0       1       0  \n",
       "...      ...   ...     ...     ...  \n",
       "69296      1     0       1       0  \n",
       "69297      0     0       1       1  \n",
       "69298      0     1       0       1  \n",
       "69299      0     0       0       1  \n",
       "69300      0     0       1       0  \n",
       "\n",
       "[69301 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos\n",
    "# Las dos primeras columnas contienen la nota de dos examenes y la tercera columna\n",
    "data = pd.read_csv('./cardio_train.csv', delimiter=';')\n",
    "\n",
    "# Configurar Pandas para que no corte la visualización\n",
    "pd.set_option('display.max_rows', 100)  # Mostrar todas las filas (60 -> None)\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas (20 -> None)\n",
    "\n",
    "# Mostramos los datos\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESAMIENTO DE LOS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMACION DE TIPO DE DATOS\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69301 entries, 0 to 69300\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           69301 non-null  int64  \n",
      " 1   age          69301 non-null  int64  \n",
      " 2   gender       69301 non-null  int64  \n",
      " 3   height       69301 non-null  int64  \n",
      " 4   weight       69301 non-null  float64\n",
      " 5   ap_hi        69301 non-null  int64  \n",
      " 6   ap_lo        69301 non-null  int64  \n",
      " 7   cholesterol  69301 non-null  int64  \n",
      " 8   gluc         69301 non-null  int64  \n",
      " 9   smoke        69301 non-null  int64  \n",
      " 10  alco         69301 non-null  int64  \n",
      " 11  active       69301 non-null  int64  \n",
      " 12  cardio       69301 non-null  int64  \n",
      "dtypes: float64(1), int64(12)\n",
      "memory usage: 6.9 MB\n",
      "\n",
      "DATOS VACIOS\n",
      "id             0\n",
      "age            0\n",
      "gender         0\n",
      "height         0\n",
      "weight         0\n",
      "ap_hi          0\n",
      "ap_lo          0\n",
      "cholesterol    0\n",
      "gluc           0\n",
      "smoke          0\n",
      "alco           0\n",
      "active         0\n",
      "cardio         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Leemos el tipo de datos que tiene el dataset y vemos los datos faltantes\n",
    "print('INFORMACION DE TIPO DE DATOS')\n",
    "data.info()\n",
    "print('\\nDATOS VACIOS')\n",
    "print(pd.isnull(data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no son necesarias para el modelamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso eliminamos la columna ID\n",
    "data.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez procesado el dataset lo mostramos y aplicamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22469</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>69.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14648</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>71.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21901</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14549</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>85.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23393</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69296</th>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69297</th>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69298</th>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69299</th>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69300</th>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69301 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0      22469       1     155    69.0    130     80            2     2      0   \n",
       "1      14648       1     163    71.0    110     70            1     1      0   \n",
       "2      21901       1     165    70.0    120     80            1     1      0   \n",
       "3      14549       2     165    85.0    120     80            1     1      1   \n",
       "4      23393       1     155    62.0    120     80            1     1      0   \n",
       "...      ...     ...     ...     ...    ...    ...          ...   ...    ...   \n",
       "69296  19240       2     168    76.0    120     80            1     1      1   \n",
       "69297  22601       1     158   126.0    140     90            2     2      0   \n",
       "69298  19066       2     183   105.0    180     90            3     1      0   \n",
       "69299  22431       1     163    72.0    135     80            1     2      0   \n",
       "69300  20540       1     170    72.0    120     80            2     1      0   \n",
       "\n",
       "       alco  active  cardio  \n",
       "0         0       1       0  \n",
       "1         0       1       1  \n",
       "2         0       1       0  \n",
       "3         1       1       0  \n",
       "4         0       1       0  \n",
       "...     ...     ...     ...  \n",
       "69296     0       1       0  \n",
       "69297     0       1       1  \n",
       "69298     1       0       1  \n",
       "69299     0       0       1  \n",
       "69300     0       1       0  \n",
       "\n",
       "[69301 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos el dataset procesado\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69301, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos información \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logistica Binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de X_train:\n",
      "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "20241  17230       1     153   115.0    120     80            3     3      0   \n",
      "36773  20257       1     166   103.0    140     90            3     3      0   \n",
      "39989  18885       1     162    91.0    150     90            1     1      0   \n",
      "59583  20306       1     160    62.0    130     90            1     1      0   \n",
      "67792  21987       1     168    72.0    120     80            3     3      0   \n",
      "...      ...     ...     ...     ...    ...    ...          ...   ...    ...   \n",
      "37194  21891       1     155    79.0    120     80            1     1      0   \n",
      "6265   18280       1     155   105.0    120     80            1     1      0   \n",
      "54886  23260       1     158    68.0    130     80            1     1      0   \n",
      "860    17317       2     165    70.0    160     90            1     1      0   \n",
      "15795  16846       1     168    69.0    130     80            1     1      0   \n",
      "\n",
      "       alco  active  \n",
      "20241     0       1  \n",
      "36773     0       1  \n",
      "39989     0       0  \n",
      "59583     0       0  \n",
      "67792     0       0  \n",
      "...     ...     ...  \n",
      "37194     0       1  \n",
      "6265      0       0  \n",
      "54886     0       1  \n",
      "860       0       1  \n",
      "15795     0       1  \n",
      "\n",
      "[55440 rows x 11 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Datos de y_train:\n",
      "20241    1\n",
      "36773    0\n",
      "39989    1\n",
      "59583    0\n",
      "67792    1\n",
      "        ..\n",
      "37194    0\n",
      "6265     0\n",
      "54886    0\n",
      "860      1\n",
      "15795    0\n",
      "Name: cardio, Length: 55440, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "El 80% de ejemplos que seran para el entrenamiento son: 55440\n",
      "El 20% de ejemplos que seran para el entrenamiento son: 13861\n"
     ]
    }
   ],
   "source": [
    "# Leemos los datos del dataset\n",
    "\n",
    "# Aplicando la libreria, separamos los datos del 80% y 20% del Dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividimos los datos para X_test y y_test donde seran los datos para el prueba \n",
    "X_test = test_data.drop(['cardio'], axis=1)\n",
    "y_test = test_data['cardio']\n",
    "\n",
    "# Dividimos los datos para X_train y y_train donde seran los datos para el entrenamiento\n",
    "X_train = train_data.drop(['cardio'], axis=1)\n",
    "y_train = train_data['cardio']\n",
    "m_train = len(y_train)\n",
    "\n",
    "\n",
    "# Mostramos los datos que seran para el entrenamiento\n",
    "print(\"Datos de X_train:\")\n",
    "print(X_train)\n",
    "print('-' * 100)\n",
    "print(\"Datos de y_train:\")\n",
    "print(y_train)\n",
    "\n",
    "# Mostramos la cantidad de ejemplos que tienen X_train y y_train\n",
    "print('-' * 80)\n",
    "print(\"El 80% de ejemplos que seran para el entrenamiento son: {:.0f}\".format(len(train_data)))\n",
    "print(\"El 20% de ejemplos que seran para el entrenamiento son: {:.0f}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>17230</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>115.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>20257</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>103.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>18885</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>91.0</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59583</th>\n",
       "      <td>20306</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67792</th>\n",
       "      <td>21987</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>21891</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>79.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>18280</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>105.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>23260</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>68.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>17317</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>16846</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>69.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55440 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "20241  17230       1     153   115.0    120     80            3     3      0   \n",
       "36773  20257       1     166   103.0    140     90            3     3      0   \n",
       "39989  18885       1     162    91.0    150     90            1     1      0   \n",
       "59583  20306       1     160    62.0    130     90            1     1      0   \n",
       "67792  21987       1     168    72.0    120     80            3     3      0   \n",
       "...      ...     ...     ...     ...    ...    ...          ...   ...    ...   \n",
       "37194  21891       1     155    79.0    120     80            1     1      0   \n",
       "6265   18280       1     155   105.0    120     80            1     1      0   \n",
       "54886  23260       1     158    68.0    130     80            1     1      0   \n",
       "860    17317       2     165    70.0    160     90            1     1      0   \n",
       "15795  16846       1     168    69.0    130     80            1     1      0   \n",
       "\n",
       "       alco  active  \n",
       "20241     0       1  \n",
       "36773     0       1  \n",
       "39989     0       0  \n",
       "59583     0       0  \n",
       "67792     0       0  \n",
       "...     ...     ...  \n",
       "37194     0       1  \n",
       "6265      0       0  \n",
       "54886     0       1  \n",
       "860       0       1  \n",
       "15795     0       1  \n",
       "\n",
       "[55440 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si es mas posible podemos visualizar los omportamientos de los datos en una grafica\n",
    "\n",
    "## 1.1 **Visualizar los datos en la gráfica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotData(X, y):\n",
    "  # Gragica los puntos de datos X y y en una nueva figura. Grafica los puntos de datos con * para los positivos y\n",
    "  # o para los negativos.\n",
    "\n",
    "  # Crear una nueva figura\n",
    "  fig = plt.figure()\n",
    "\n",
    "  # Encontrar indices de positivos y negativos\n",
    "  pos = y == 1\n",
    "  neg = y == 0\n",
    "\n",
    "  plt.plot(X[pos, 0], X[pos, 1], 'k*', lw=2, ms=10)\n",
    "  plt.plot(X[neg, 0], X[neg, 1], 'ko', mfc='y', ms=8, mec='k', mew=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.2 IMPLEMENTACIÓN**\n",
    "\n",
    "## **1.2.1 Normalización de los datos:**\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. Se aplica la normalizacion esto debido a que los datos de las X estan a diferentes escalas.\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos de las columnas X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la funcion de normalizacion de datos\n",
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "\n",
    "    sigma[sigma == 0] = 1  # verificar\n",
    "\n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>-0.903802</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.383913</td>\n",
       "      <td>2.837900</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>0.322579</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>2.003259</td>\n",
       "      <td>0.078345</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>-0.233283</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.287788</td>\n",
       "      <td>1.168619</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59583</th>\n",
       "      <td>0.342431</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.531371</td>\n",
       "      <td>-0.848427</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67792</th>\n",
       "      <td>1.023483</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.442962</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>0.984589</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.140330</td>\n",
       "      <td>0.333979</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>-0.478397</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.140330</td>\n",
       "      <td>2.142366</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>1.539236</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.774955</td>\n",
       "      <td>-0.431107</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.868554</td>\n",
       "      <td>1.364176</td>\n",
       "      <td>0.077587</td>\n",
       "      <td>-0.292001</td>\n",
       "      <td>0.216294</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-1.059378</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.442962</td>\n",
       "      <td>-0.361554</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55440 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    gender    height    weight     ap_hi     ap_lo  \\\n",
       "20241 -0.903802 -0.733043 -1.383913  2.837900 -0.059603 -0.094061   \n",
       "36773  0.322579 -0.733043  0.199379  2.003259  0.078345 -0.034559   \n",
       "39989 -0.233283 -0.733043 -0.287788  1.168619  0.147319 -0.034559   \n",
       "59583  0.342431 -0.733043 -0.531371 -0.848427  0.009371 -0.034559   \n",
       "67792  1.023483 -0.733043  0.442962 -0.152894 -0.059603 -0.094061   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "37194  0.984589 -0.733043 -1.140330  0.333979 -0.059603 -0.094061   \n",
       "6265  -0.478397 -0.733043 -1.140330  2.142366 -0.059603 -0.094061   \n",
       "54886  1.539236 -0.733043 -0.774955 -0.431107  0.009371 -0.094061   \n",
       "860   -0.868554  1.364176  0.077587 -0.292001  0.216294 -0.034559   \n",
       "15795 -1.059378 -0.733043  0.442962 -0.361554  0.009371 -0.094061   \n",
       "\n",
       "       cholesterol      gluc    smoke      alco    active  \n",
       "20241     2.406517  3.103155 -0.31186 -0.238634  0.494978  \n",
       "36773     2.406517  3.103155 -0.31186 -0.238634  0.494978  \n",
       "39989    -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "59583    -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "67792     2.406517  3.103155 -0.31186 -0.238634 -2.020291  \n",
       "...            ...       ...      ...       ...       ...  \n",
       "37194    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "6265     -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "54886    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "860      -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "15795    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "\n",
       "[55440 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamamos a la funcion de normalización para normalizar los datos de X_train\n",
    "X_train_norm, mu, sigma = featureNormalize(X_train)\n",
    "\n",
    "# Mostramos los datos ya normalizados\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despues de normalizar los datos el siguiente procedimiento es añadir la columna de unos (1) para los thetas 0, esto para que  todos los valores estén en un rango entre -1 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.90380193, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        ,  0.32257868, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -0.2332833 , -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407, -2.0202912 ],\n",
       "       ...,\n",
       "       [ 1.        ,  1.53923574, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -0.86855412,  1.36417608, ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -1.05937845, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antes de continuar es importante agregar el termino de intercepcion a X.\n",
    "# Agregamos la columna de 1\n",
    "m, n = X_train.shape\n",
    "\n",
    "# Agraga el termino de intercepción a A\n",
    "X_train_ready = np.concatenate([np.ones((m, 1)), X_train_norm], axis=1)\n",
    "\n",
    "# Mostramos los datos con la columna de unos\n",
    "X_train_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 FUNCIÓN SIGMOIDEA**\n",
    "\n",
    "La función sigmoidea o tambien llamada función de logistica, nos permite calcaluar o predecir una probabilidad de un hecho que de 0 a 1.\n",
    "Donde z es la theta transpuesta por X, que es nuestra hipótesis. Esta funcion nos permite predecir valores entre 1 y 0 para ver en que estado se encuentra. En este caso si una persona tiene enfermedad cardiovascular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la función sigmoidea o funcion logistica que calcula la hipotesis ho(x)\n",
    "def sigmoid(z):\n",
    "  # Calcula la sigmoidea de una entrada z\n",
    "  # convierte la entrada a un arreglo numpy\n",
    "  z = np.array(z)\n",
    "  g = np.zeros(z.shape)\n",
    "\n",
    "  g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "  return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el valor de la sigmoide aplicando la funcion sigmoid con `z=0`, se debe obtener un resultado de 0.5. RE recomienda experimentar con otros valores de `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "g( [0, 0.5, 1] ) =  [0.5        0.62245933 0.73105858]\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(0))\n",
    "\n",
    "\n",
    "# Prueba la implementación de la funcion sigmoidea\n",
    "z = [0, 0.5, 1]\n",
    "g = sigmoid(z)\n",
    "\n",
    "print('g(', z, ') = ', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 FUNCIÓN DE COSTO Y GRADIENTE**\n",
    "\n",
    "Se implementa la funcion cost y gradient, para la regresión logistica, donde hace el uso de la funcion de Sigmoid para calular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cálculo del costo  J(θ)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funcion de costo en una regresión logistica es:\n",
    "def calcularCosto(theta, X, y):\n",
    "  m = y.size # numeros de ejemplos de entrenamiento\n",
    "\n",
    "  J = 0\n",
    "  h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "  J = - (1 / m) * np.sum(y.dot(np.log(h)) + (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "  return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso por el gradiente\n",
    "\n",
    "El costo $J(\\theta)$ esta parametrizado por el vector $\\theta$, no $X$ y $y$. Donde hay que minimizar el valor de $J(\\theta)$ cambiando los valores del vector $\\theta$. Una buena manera de verificar si el descenso por el gradiente esta trabajando correctamente es ver los valores de $J(\\theta)$ y verificar si estos decresen en cada paso.\n",
    "\n",
    "Creamos la funcion para calcular el descenso por la gradiente y obtener un theta y J_historico. haciendo uso de la **sigmoid()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la funcion del Descenso por el gradiente\n",
    "def descensoGradiente(theta, X, y, alpha, num_iters):\n",
    "  m = y.shape[0]\n",
    "\n",
    "  # realizar una copia de theta, el cual será actualizada por el descenso por el gradiente\n",
    "  theta = theta.copy()\n",
    "  J_history = []\n",
    "\n",
    "  for i in range(num_iters):\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    theta = theta - (alpha / m) * (h - y).dot(X)\n",
    "\n",
    "    J_history.append(calcularCosto(theta, X, y))\n",
    "    \n",
    "  return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probamos con algunos alternativas, donde los thetas se inicializan con Cero (0) y con una taza de aprendizaje alpha por lo que hacemos pruebas con diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55440, 12)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antes verificamos el tamaño del tadaset para incluir la cantidad de thetas como parámetros\n",
    "X_train_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetas calculados por el descenso por el gradiente: [ 0.00747984  0.39845218  0.01686302 -0.05285928  0.31022518  0.18605193\n",
      "  0.16177904  0.34379589  0.00395399 -0.02593653 -0.0272736  -0.06342675]\n",
      "====================================================================================================\n",
      "Con un costo de: 0.6263320282266498 \n",
      "====================================================================================================\n",
      "GRÁFICA DE LA CONVERGENCIA DEL COSTO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Resultado')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABboElEQVR4nO3deVxU5f4H8M/MMAvrgCzDIogb7qCiIqJ5u2JYZnbzmnUtl9LKSFHL1J+prejNa9dKr6a30rarZW4lSYpLaq64byCigsgqsi8DM+f3x+jRCTRZz8B83q/XvJg585wz33NQ5+N5nvMcmSAIAoiIiIisiFzqAoiIiIgaGwMQERERWR0GICIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq2MjdQGWyGg04vr163B0dIRMJpO6HCIiInoAgiCgsLAQ3t7ekMvvf46HAaga169fh6+vr9RlEBERUS2kpqaiZcuW923DAFQNR0dHAKYD6OTkJHE1RERE9CAKCgrg6+srfo/fDwNQNW53ezk5OTEAERERNTEPMnyFg6CJiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVoc3Q21E8Vdv4siVXOQUluOtxztLXQ4REZHVYgBqRLM3nEJiZhEUchmmPxIAOxUPPxERkRTYBdaIevm3AAAYjAJOpORJWwwREZEVYwBqRL39XcTnR67clLASIiIi68YA1Ih6tWohPj96NVfCSoiIiKwbA1AjauliC52TGgBw7OpNVBqMEldERERknRiAGpFMJhPHARXrDbiQUShxRURERNaJAaiR9W51ZxzQ0SvsBiMiIpICA1Aju30GCACOXOVAaCIiIikwADWyjp6OsFcpAJjOAAmCIHFFRERE1ocBqJHZKOToeasbLLOgHNdulkpcERERkfVhAJIAL4cnIiKSFgOQBDghIhERkbQYgCTQ3c8ZCrkMAK8EIyIikoLkAWjZsmXw9/eHRqNBSEgIDh8+fN/2eXl5iIyMhJeXF9RqNQICAhATEyO+X1hYiKlTp6JVq1awtbVFv379cOTIkYbejRqxU9mgi7cTACAxswj5JRUSV0RERGRdJA1A69atw/Tp0zF//nwcO3YMQUFBiIiIQFZWVrXt9Xo9Bg8ejCtXrmD9+vVISEjAqlWr4OPjI7aZMGECtm/fjq+//hqnT5/GI488gvDwcKSlpTXWbj2Qu8cBxafwLBAREVFjkgkSXocdEhKC3r17Y+nSpQAAo9EIX19fTJ48GbNmzarSfsWKFVi0aBEuXLgApVJZ5f3S0lI4Ojpi8+bNGDp0qLg8ODgYjz76KN5///0HqqugoABarRb5+flwcnKq5d7d3y+n0zHp22MAgEl/aYuZQzo2yOcQERFZi5p8f0t2Bkiv1yM+Ph7h4eF3ipHLER4ejgMHDlS7zpYtWxAaGorIyEjodDp07doV0dHRMBgMAIDKykoYDAZoNBqz9WxtbbFv37571lJeXo6CggKzR0ML9ueM0ERERFKRLADl5OTAYDBAp9OZLdfpdMjIyKh2neTkZKxfvx4GgwExMTGYO3cuFi9eLJ7ZcXR0RGhoKN577z1cv34dBoMB33zzDQ4cOID09PR71rJgwQJotVrx4evrW387eg8ejhr4u9oBAE6m5qOswtDgn0lEREQmkg+Crgmj0QgPDw+sXLkSwcHBGDVqFObMmYMVK1aIbb7++msIggAfHx+o1Wp88sknePbZZyGX33tXZ8+ejfz8fPGRmpraGLuDPq1N44D0BiNOpOY1ymcSERGRhAHIzc0NCoUCmZmZZsszMzPh6elZ7TpeXl4ICAiAQqEQl3Xq1AkZGRnQ6/UAgLZt22LPnj0oKipCamoqDh8+jIqKCrRp0+aetajVajg5OZk9GkNIa1fx+cHkG43ymURERCRhAFKpVAgODkZcXJy4zGg0Ii4uDqGhodWuExYWhqSkJBiNRnFZYmIivLy8oFKpzNra29vDy8sLN2/eRGxsLIYPH94wO1IHIW3uXAl2KJnjgIiIiBqLpF1g06dPx6pVq7BmzRqcP38ekyZNQnFxMcaPHw8AGDNmDGbPni22nzRpEnJzcxEVFYXExERs3boV0dHRiIyMFNvExsZi27ZtuHz5MrZv346HH34YHTt2FLdpSVq62KGliy0A4FjKTZRXchwQERFRY7CR8sNHjRqF7OxszJs3DxkZGejevTu2bdsmDoxOSUkxG7vj6+uL2NhYTJs2DYGBgfDx8UFUVBRmzpwptsnPz8fs2bNx7do1tGjRAiNGjMAHH3xQ7WXzlqBvG1esj7+G8kojTqbmi+OCiIiIqOFIOg+QpWqMeYBu++FoKmasPwUAmD44AFMGtW/QzyMiImqumsQ8QGTSt82dgdCHLnMgNBERUWNgAJKYbws7+DibxgHFX+U4ICIiosbAAGQBbl8NVlZhxKlr+RJXQ0RE1PwxAFmAvnfNB3SI8wERERE1OAYgC3D3OKCDnA+IiIiowTEAWQDfFrbw0ppu4Bp/9Sb0lcY/WYOIiIjqggHIAshkMvEsUGmFAafT8qQtiIiIqJljALIQIXdNgMhuMCIioobFAGQhzMcBcSA0ERFRQ2IAshCtXO3g6WQaB3T0CscBERERNSQGIAshk8nQr+2dcUDHU25KXBEREVHzxQBkQcLauYnP9yflSFgJERFR88YAZEHMAtAljgMiIiJqKAxAFsRTq0Fbd3sAwInUPBSWVUhcERERUfPEAGRhbp8FMhgFHL7My+GJiIgaAgOQhTEfB8RuMCIioobAAGRh+rZxhVxmes6B0ERERA2DAcjCaG2V6NbSGQCQkFmIrMIyaQsiIiJqhhiALFBY2zuzQh/g1WBERET1jgHIAnE+ICIioobFAGSBglu5QG1j+tXsT7oBQRAkroiIiKh5YQCyQBqlAr38XQAAaXmluHqjROKKiIiImhcGIAtlPis0u8GIiIjqEwOQhQpreycA7bvIAERERFSfGIAsVFcfLbS2SgCmgdCVBqPEFRERETUfDEAWSiGXoX9701mggrJKnLyWL3FFREREzQcDkAUb2N5dfL4nMVvCSoiIiJoXBiAL9lDAnQD0GwMQERFRvWEAsmCeWg066BwBACev5eFmsV7iioiIiJoHBiALN7CD6SyQIAB7OSs0ERFRvWAAsnAPtWc3GBERUX1jALJwvfxdYKtUADAFIN4Wg4iIqO4YgCycRqlA3zYtAABZheW4kFEocUVERERNHwNQEzAwgJfDExER1ScGoCbg7svh9yQwABEREdUVA1AT0NrNHr4tbAEAR6/mori8UuKKiIiImjYGoCZAJpOJV4NVGAQcuHRD4oqIiIiaNgagJoLjgIiIiOoPA1AT0a+dG5QKGQBgV0IWL4cnIiKqA8kD0LJly+Dv7w+NRoOQkBAcPnz4vu3z8vIQGRkJLy8vqNVqBAQEICYmRnzfYDBg7ty5aN26NWxtbdG2bVu89957TT4wOKhtENLaFQBw7WYpLmYVSVwRERFR02Uj5YevW7cO06dPx4oVKxASEoIlS5YgIiICCQkJ8PDwqNJer9dj8ODB8PDwwPr16+Hj44OrV6/C2dlZbPPPf/4Ty5cvx5o1a9ClSxccPXoU48ePh1arxZQpUxpx7+rfXzt6YN+t22HEnc9CwK37hBEREVHNyAQJT42EhISgd+/eWLp0KQDAaDTC19cXkydPxqxZs6q0X7FiBRYtWoQLFy5AqVRWu83HH38cOp0On3/+ubhsxIgRsLW1xTfffPNAdRUUFECr1SI/Px9OTk612LOGcfVGMQYu2g0A6O3vgh9e6SdtQURERBakJt/fknWB6fV6xMfHIzw8/E4xcjnCw8Nx4MCBatfZsmULQkNDERkZCZ1Oh65duyI6OhoGg0Fs069fP8TFxSExMREAcPLkSezbtw+PPvroPWspLy9HQUGB2cMStXK1R1t3ewBA/NWbvDs8ERFRLUkWgHJycmAwGKDT6cyW63Q6ZGRkVLtOcnIy1q9fD4PBgJiYGMydOxeLFy/G+++/L7aZNWsWnnnmGXTs2BFKpRI9evTA1KlTMXr06HvWsmDBAmi1WvHh6+tbPzvZAAZ1Mh0vo8CrwYiIiGpL8kHQNWE0GuHh4YGVK1ciODgYo0aNwpw5c7BixQqxzffff49vv/0W3333HY4dO4Y1a9bgX//6F9asWXPP7c6ePRv5+fniIzU1tTF2p1b+2vHO2Ki4C1kSVkJERNR0STYI2s3NDQqFApmZmWbLMzMz4enpWe06Xl5eUCqVUCgU4rJOnTohIyMDer0eKpUKM2bMEM8CAUC3bt1w9epVLFiwAGPHjq12u2q1Gmq1up72rGEFt3KBk8YGBWWV2JOQhQqDEUpFk8qxREREkpPsm1OlUiE4OBhxcXHiMqPRiLi4OISGhla7TlhYGJKSkmA0GsVliYmJ8PLygkqlAgCUlJRALjffLYVCYbZOU6ZUyDGwg+ksUEFZJeKv3pS4IiIioqZH0lMH06dPx6pVq7BmzRqcP38ekyZNQnFxMcaPHw8AGDNmDGbPni22nzRpEnJzcxEVFYXExERs3boV0dHRiIyMFNsMGzYMH3zwAbZu3YorV65g48aN+Oijj/C3v/2t0fevoQy6qxtsJ7vBiIiIakzSeYBGjRqF7OxszJs3DxkZGejevTu2bdsmDoxOSUkxO5vj6+uL2NhYTJs2DYGBgfDx8UFUVBRmzpwptvn0008xd+5cvPrqq8jKyoK3tzdefvllzJs3r9H3r6EMDHCHXGYaCB13PhP/91gnqUsiIiJqUiSdB8hSWeo8QHcbueJ3HLli6v7a/cZf4O9mL3FFRERE0moS8wBR3fy1453pA3g1GBERUc0wADVRgzrdGQe041zmfVoSERHRHzEANVHtPRzQytUOAHD4Si5nhSYiIqoBBqAmSiaTIaKLab4kg1FgNxgREVENMAA1YY90vjMOKPZs9bcPISIioqoYgJqwnn4ucHMwzWD9W2I2SvSVEldERETUNDAANWFyuQyDb50FKq804rfEHIkrIiIiahoYgJq4R7rc6Qb7ld1gRERED4QBqInr19YVDmrThN47zmeiwtA87nlGRETUkBiAmji1jQIPd7xzc9RDybkSV0RERGT5GICagbuvBvv1HLvBiIiI/gwDUDPwlw7uUClMv8pfz2bCaOTt3YiIiO6HAagZcNQoEdbOFQCQUVCGU2n5EldERERk2RiAmolHbs0KDQDbzrAbjIiI6H4YgJqJwZ11kMtMz385kw5BYDcYERHRvTAANRNuDmr0bWPqBrt6owRnrxdIXBEREZHlYgBqRh7r5iU+33o6XcJKiIiILBsDUDMypKun2A229RS7wYiIiO6FAagZcXNQI7StqRssJZfdYERERPfCANTM3N0N9vMpdoMRERFVhwGomRnS5U43WMxpdoMRERFVhwGomXF1UKNfWzcApm6wM2nsBiMiIvojBqBmyKwb7PR1CSshIiKyTAxAzVBEFx0Ut/rB2A1GRERUFQNQM2TqBjNdDZaaW4rTvDcYERGRGQagZopXgxEREd0bA1AzFdHFEza3usF+OnkdRiO7wYiIiG5jAGqmWtir8FCAOwAgPb8Mhy7nSlwRERGR5WAAasaGd/cWn285mSZhJURERJaFAagZG9xZBzuVAoDp3mDllQaJKyIiIrIMDEDNmJ3KBhFdPAEABWWV2J2QLXFFREREloEBqJm7uxts8wl2gxEREQEMQM1e/3ZucLVXAQB2nM9CQVmFxBURERFJjwGombNRyPF4oGlOIH2lEbFnMiSuiIiISHoMQFZgeA8f8fnmE7w3GBEREQOQFejh64xWrnYAgN8v5SCroEziioiIiKTFAGQFZDIZhgeZBkMbBWDLSZ4FIiIi68YAZCWe6H6nG+zHY7wajIiIrBsDkJVo5+GA7r7OAIDz6QU4e513iCciIuvFAGRF/h7cUnz+w9FrElZCREQkLYsIQMuWLYO/vz80Gg1CQkJw+PDh+7bPy8tDZGQkvLy8oFarERAQgJiYGPF9f39/yGSyKo/IyMiG3hWLNizIGyob069884k06CuNEldEREQkDckD0Lp16zB9+nTMnz8fx44dQ1BQECIiIpCVlVVte71ej8GDB+PKlStYv349EhISsGrVKvj43BnjcuTIEaSnp4uP7du3AwBGjhzZKPtkqbS2SvHWGDdLKrDzQqbEFREREUlDJgiCIGUBISEh6N27N5YuXQoAMBqN8PX1xeTJkzFr1qwq7VesWIFFixbhwoULUCqVD/QZU6dOxc8//4yLFy9CJpNVeb+8vBzl5eXi64KCAvj6+iI/Px9OTk613DPL9FtiNsZ8YTrDFt7JA/8d21viioiIiOpHQUEBtFrtA31/S3oGSK/XIz4+HuHh4eIyuVyO8PBwHDhwoNp1tmzZgtDQUERGRkKn06Fr166Ijo6GwVD9nc71ej2++eYbvPDCC9WGHwBYsGABtFqt+PD19a37zlmosHZu8NJqAAC7ErKRVcg5gYiIyPpIGoBycnJgMBig0+nMlut0OmRkVH/LhuTkZKxfvx4GgwExMTGYO3cuFi9ejPfff7/a9ps2bUJeXh7GjRt3zzpmz56N/Px88ZGamlrrfbJ0CrkMT/U0dRcajAI2H+ecQEREZH0kHwNUU0ajER4eHli5ciWCg4MxatQozJkzBytWrKi2/eeff45HH30U3t7e1b4PAGq1Gk5OTmaP5mxEzztXg62PvwaJe0GJiIganaQByM3NDQqFApmZ5oNxMzMz4enpWe06Xl5eCAgIgEKhEJd16tQJGRkZ0Ov1Zm2vXr2KHTt2YMKECfVffBPWxt0BvVq5AAASMgtxOo1zAhERkXWRNACpVCoEBwcjLi5OXGY0GhEXF4fQ0NBq1wkLC0NSUhKMxjuXcCcmJsLLywsqlcqs7ZdffgkPDw8MHTq0YXagCbt7TqDvjzbfLj8iIqLqSN4FNn36dKxatQpr1qzB+fPnMWnSJBQXF2P8+PEAgDFjxmD27Nli+0mTJiE3NxdRUVFITEzE1q1bER0dXWWOH6PRiC+//BJjx46FjY1No+5TUzA00Au2StNZtM3Hr6NEXylxRURERI1H8mQwatQoZGdnY968ecjIyED37t2xbds2cWB0SkoK5PI7Oc3X1xexsbGYNm0aAgMD4ePjg6ioKMycOdNsuzt27EBKSgpeeOGFRt2fpsJRo8SwIC98f/QaCssr8fOpdDzdq/le/UZERHQ3yecBskQ1mUegKTuechN/+8/vAIAefs7Y+GqYxBURERHVXpOZB4ik1d3XGR09HQEAx1PycD69QOKKiIiIGgcDkBWTyWQYHeInvv7f4RQJqyEiImo8DEBWbngPH2iUpj8GG4+loVRf/YzaREREzQkDkJVz0igxLNA0SWRheSV+OsWZoYmIqPljACL8g91gRERkZRiAiIOhiYjI6jAAEWQyGc8CERGRVWEAIgDAkz18xJmhNxxLQ1E5Z4YmIqLmiwGIAJgGQz/ZwzQYuqi8EhuOXZO4IiIioobDAESiMaH+4vM1v18BJwknIqLmigGIRJ28nNCndQsAwKXsYuxPuiFxRURERA2DAYjMjOvnLz5f/fsVyeogIiJqSAxAZGZwZx08nTQAgLgLmUjNLZG4IiIiovrHAERmlAo5nutruiReEIBvDl6VuCIiIqL6V+sAtGfPHgwbNgzt2rVDu3bt8MQTT2Dv3r31WRtJ5Jk+flApTH801h5J5f3BiIio2alVAPrmm28QHh4OOzs7TJkyBVOmTIGtrS0GDRqE7777rr5rpEbm5qDG44FeAID80gpsOZkmcUVERET1SybU4lrnTp064aWXXsK0adPMln/00UdYtWoVzp8/X28FSqGgoABarRb5+flwcnKSuhxJnEzNw/Bl+wEAHT0d8UvUAMhkMomrIiIiureafH/X6gxQcnIyhg0bVmX5E088gcuXL9dmk2Rhgnyd0d3XGQBwIaMQv1/iJfFERNR81CoA+fr6Ii4ursryHTt2wNfXt85FkWV4sX9r8fnK35IlrISIiKh+2dRmpddffx1TpkzBiRMn0K9fPwDA/v37sXr1anz88cf1WiBJ59GunvBxtkVaXin2JGYjMbMQATpHqcsiIiKqs1qdAZo0aRLWrl2L06dPY+rUqZg6dSrOnDmDdevW4eWXX67vGkkiNgo5XrjrLNB/9/IsEBERNQ+1GgTd3HEQ9B1F5ZUIXRCHwrJKqBRy7Jv1MDwcNVKXRUREVEWDD4Im6+GgtsE/+pgmRtQbjPj6ACdGJCKipu+BxwC5uLg88GXQubm5tS6ILM+4MH98vu8yKo0Cvj54FZP+0hZ2qloNHyMiIrIID/wttmTJEvH5jRs38P777yMiIgKhoaEAgAMHDiA2NhZz586t9yJJWl5aWwwL8sbG42nIK6nAj/HX8Hyov9RlERER1VqtxgCNGDECDz/8MF577TWz5UuXLsWOHTuwadOm+qpPEhwDVNXZ6/kY+sk+AIC/qx3iXv8LFHJOjEhERJajwccAxcbGYsiQIVWWDxkyBDt27KjNJsnCdfHWol9bVwDAlRsl+OVMusQVERER1V6tApCrqys2b95cZfnmzZvh6upa56LIMk36S1vx+bJdl8ALCImIqKmq1UjWd955BxMmTMDu3bsREhICADh06BC2bduGVatW1WuBZDn6t3NDYEstTl3Lx/n0AuxOyMbDHT2kLouIiKjGanUGaNy4cdi/fz+cnJywYcMGbNiwAU5OTti3bx/GjRtXzyWSpZDJZIh8uJ34eumuJJ4FIiKiJqnW1zKHhITg22+/rc9aqAkY3EmH9h4OuJhVhPirN3H4ci5C2rDbk4iImpY6T4RYVlaGgoICswc1X3K5DK8+fGcs0NJdSRJWQ0REVDu1CkAlJSV47bXX4OHhAXt7e7i4uJg9qHkbFugN3xa2AIC9F3Nw6lqetAURERHVUK0C0IwZM7Bz504sX74carUa//3vf/HOO+/A29sbX331VX3XSBbGRiHHKwPvnAX6z65LElZDRERUc7UKQD/99BP+85//YMSIEbCxscGAAQPw1ltvITo6muOCrMSIni3h4agGAGw7m4HEzEKJKyIiInpwtQpAubm5aNOmDQDAyclJvPdX//798dtvv9VfdWSxNEoFJg5oI77+OO6ihNUQERHVTK0CUJs2bXD58mUAQMeOHfH9998DMJ0ZcnZ2rrfiyLI917cV3BxMZ4G2nkrHhQwOgCcioqahVgFo/PjxOHnyJABg1qxZWLZsGTQaDaZNm4YZM2bUa4FkuWxVCrwy8M5ZoCXbeRaIiIiahlrdDPWPrl69ivj4eLRr1w6BgYH1UZekeDPUB1dWYcCAD3chu7AcALB1Sn908dZKXBUREVmjBr8Z6ldffYXy8nLxdatWrfDUU0+hY8eONb4KbNmyZfD394dGo0FISAgOHz583/Z5eXmIjIyEl5cX1Go1AgICEBMTY9YmLS0Nzz33HFxdXWFra4tu3brh6NGjNaqLHoxGqcCrd90jbMkOngUiIiLLV+susPz8/CrLCwsLMX78+Afezrp16zB9+nTMnz8fx44dQ1BQECIiIpCVlVVte71ej8GDB+PKlStYv349EhISsGrVKvj4+Ihtbt68ibCwMCiVSvzyyy84d+4cFi9ezPmJGtCzffygczKNBdp+LhOnr1X9s0FERGRJatUFJpfLkZmZCXd3d7PlJ0+exMMPPyxeFfZnQkJC0Lt3byxduhQAYDQa4evri8mTJ2PWrFlV2q9YsQKLFi3ChQsXoFQqq93mrFmzsH//fuzdu7eGe3UHu8Bq7usDVzB381kAwKCOHvh8XG+JKyIiImvTYF1gPXr0QM+ePSGTyTBo0CD07NlTfAQFBWHAgAEIDw9/oG3p9XrEx8ebtZfL5QgPD8eBAweqXWfLli0IDQ1FZGQkdDodunbtiujoaBgMBrM2vXr1wsiRI+Hh4YEePXr86R3qy8vLeTuPOnq6ty+8tRoAQNyFLJxIzZO2ICIiovuo0c1Qn3zySQDAiRMnEBERAQcHB/E9lUoFf39/jBgx4oG2lZOTA4PBAJ1OZ7Zcp9PhwoUL1a6TnJyMnTt3YvTo0YiJiUFSUhJeffVVVFRUYP78+WKb5cuXY/r06fi///s/HDlyBFOmTIFKpcLYsWOr3e6CBQvwzjvvPFDdVD21jQKRf22HORvPAAAWxV7AtxP6SlwVERFR9WrVBbZmzRqMGjUKGo2m1h98/fp1+Pj44Pfff0doaKi4/M0338SePXtw6NChKusEBASgrKwMly9fhkKhAAB89NFHWLRoEdLT0wGYglivXr3w+++/i+tNmTIFR44cueeZpfLycrNB3QUFBfD19WUXWA3pK40I/2gPUnJLAABfv9gHA9q7/8laRERE9aPBrwIbO3ZsncIPALi5uUGhUCAzM9NseWZmJjw9Patdx8vLCwEBAWL4AYBOnTohIyMDer1ebNO5c2ez9Tp16oSUlJR71qJWq+Hk5GT2oJpT2cjx+iMB4uuFv1yA0VjnWRaIiIjq3QMHIBcXF7Ro0eKBHg9CpVIhODgYcXFx4jKj0Yi4uDizM0J3CwsLQ1JSEoxGo7gsMTERXl5eUKlUYpuEhASz9RITE9GqVasH3VWqg2GB3ujibQqQZ68X4OfT6RJXREREVNUDjwFasmRJvX/49OnTMXbsWPTq1Qt9+vTBkiVLUFxcLF5KP2bMGPj4+GDBggUAgEmTJmHp0qWIiorC5MmTcfHiRURHR2PKlCniNqdNm4Z+/fohOjoaTz/9NA4fPoyVK1di5cqV9V4/VSWXyzBzSEeM+cI0n9O/YhMwpIsnVDa1OtlIRETUIB44AN1rAHFdjBo1CtnZ2Zg3bx4yMjLQvXt3bNu2TRwYnZKSArn8zhenr68vYmNjMW3aNAQGBsLHxwdRUVGYOXOm2KZ3797YuHEjZs+ejXfffRetW7fGkiVLMHr06Hqvn6o3oL0bwtq5Yn/SDaTklmDtkRSMCfWXuiwiIiJRrQZB3288DQD4+fnVuiBLwHmA6u7UtTw8sXQ/AMDNQYU9Mx6GvbpGFx0SERHVSE2+v2v1jeTv7w+ZTHbP9++el4esU2BLZwwN9MLWU+nIKdJj1d5kTA0P+PMViYiIGkGtAtDx48fNXldUVOD48eP46KOP8MEHH9RLYdT0vfFIB8SeyUClUcBne5Jv3TKjblcPEhER1YdaBaCgoKAqy3r16gVvb28sWrQITz31VJ0Lo6avtZs9Rof4Yc2BqyitMODDbQlY/HTVPztERESNrV4vzenQoQOOHDlSn5ukJm5qeACcNKac/eOxazh1LU/agoiIiFDLAPTH+2bl5+fjwoULeOutt9C+ffv6rpGaMBd7ldnYn3d/OodajLsnIiKqV7XqAnN2dq4yCFoQBPj6+mLt2rX1Uhg1H8+HtsI3h64iObsYR6/exNbT6Xg80FvqsoiIyIrVKgDt2rXL7LVcLoe7uzvatWsHGxte6kzmlAo55jzWCS+uOQoAWBBzAeGddNAoFX+yJhERUcOoVVoZOHBgfddBzdxfO3pgQHs37L2Yg7S8Uny+7zIiH24ndVlERGSlajUGaM2aNdi6dav4+s0334SzszP69euHq1ev1ltx1HzIZDK8NbQz5Ld6TpftSkJmQZm0RRERkdWqVQCKjo6Gra0tAODAgQNYunQpPvzwQ7i5uWHatGn1WiA1Hx08HfGPENMs4SV6A97fel7iioiIyFrVKgClpqaiXTtT98WmTZvw97//HS+99BIWLFiAvXv31muB1Ly8PrgDXOyUAICfTl7H/qQciSsiIiJrVKsA5ODggBs3bgAAfv31VwwePBgAoNFoUFpaWn/VUbPjYq/CzCEdxdfzNp+BvtIoYUVERGSNahWABg8ejAkTJmDChAlITEzEY489BgA4e/Ys/P3967M+aoae7uWLHn7OAIBL2cX4775kaQsiIiKrU6sAtGzZMoSGhiI7Oxs//vgjXF1dAQDx8fF49tln67VAan7kchneG95VHBD9aVwS0vJ45pCIiBqPTOC0vFUUFBRAq9UiPz8fTk5OUpfTbM3ffAZrDpiuGhzSxRMrng+WuCIiImrKavL9Xet7ge3duxfPPfcc+vXrh7S0NADA119/jX379tV2k2Rlpj/SAW4OagDAtrMZ2JWQJXFFRERkLWoVgH788UdERETA1tYWx44dQ3l5OQAgPz8f0dHR9VogNV9aWyX+77E7A6Lf2ngGxeWVElZERETWolYB6P3338eKFSuwatUqKJVKcXlYWBiOHTtWb8VR8/e3Hj4IbWMaQ5aWV4rFvyZKXBEREVmDWgWghIQEPPTQQ1WWa7Va5OXl1bUmsiIymQwLnuoGtY3pj+KXv1/G8ZSbEldFRETNXa0CkKenJ5KSkqos37dvH9q0aVPnosi6+LvZY9rgAACAIACzN5zm3EBERNSgahWAJk6ciKioKBw6dAgymQzXr1/Ht99+i9dffx2TJk2q7xrJCkzo3xpdvE0j9i9kFOKzPZckroiIiJqzWt0NftasWTAajRg0aBBKSkrw0EMPQa1WY8aMGZgwYUJ910hWwEYhxz9HBGL4sv0wGAV8ujMJj3bzQjsPB6lLIyKiZqhWZ4BkMhnmzJmD3NxcnDlzBgcPHkR2dja0Wi1at25d3zWSlejqo8WEAaY/P3qDEbN+PAWjkdNUERFR/atRACovL8fs2bPRq1cvhIWFISYmBp07d8bZs2fRoUMHfPzxx7wbPNXJtPAAtHK1AwAcvXoTX+y/LHFFRETUHNUoAM2bNw/Lly+Hv78/Ll++jJEjR+Kll17Cv//9byxevBiXL1/GzJkzG6pWsgIapQIfjgiE7NZtMj6MTUBSVqG0RRERUbNTowD0ww8/4KuvvsL69evx66+/wmAwoLKyEidPnsQzzzwDhULRUHWSFQlp44oXwm51hVUaMf37k6g08KowIiKqPzUKQNeuXUNwsOl+TV27doVarca0adMgu/3fdaJ6MiOiA9q62wMATl3Lx39286owIiKqPzUKQAaDASqVSnxtY2MDBwdepUP1T6NUYPHT3aG4dcv4T+Iu4kxavsRVERFRc1Gjy+AFQcC4ceOgVptuYFlWVoZXXnkF9vb2Zu02bNhQfxWS1eru64xX/9IWn+5MQqVRwOvfn8SWyWFQ27CrlYiI6qZGAWjs2LFmr5977rl6LYbojyb/tT3izmfhXHoBEjILsfjXRPzfY52kLouIiJo4mSAInGjlDwoKCqDVapGfnw8nJyepy7F6FzIK8MSn+6G/NRD6qxf64KEAd4mrIiIiS1OT7+9aTYRI1Jg6ejrhzSEdxNfTvz+JnKJyCSsiIqKmjgGImoQXwlpj4K2zPjlF5Zjxw0nw5CUREdUWAxA1CXK5DP8aGQQ3B9MA/F0J2fhy/xVpiyIioiaLAYiaDHdHNRY/HSS+XvjLBV4aT0REtcIARE3KwAB3TLzrhqlT1h5HcXmlxFUREVFTwwBETc6MiI7o6mMa3Z+cXYzZG05zPBAREdUIAxA1OSobOT59ticc1KZprLacvI5vDl6VuCoiImpKGICoSWrtZo8P/x4ovn7353M4kZonXUFERNSkWEQAWrZsGfz9/aHRaBASEoLDhw/ft31eXh4iIyPh5eUFtVqNgIAAxMTEiO+//fbbkMlkZo+OHTs29G5QI3usmxde7G8aD1RhEBD57THcLNZLXBURETUFkgegdevWYfr06Zg/fz6OHTuGoKAgREREICsrq9r2er0egwcPxpUrV7B+/XokJCRg1apV8PHxMWvXpUsXpKeni499+/Y1xu5QI5v1aEcEt3IBAKTllWLa9ydgNHI8EBER3Z/kAeijjz7CxIkTMX78eHTu3BkrVqyAnZ0dvvjii2rbf/HFF8jNzcWmTZsQFhYGf39/DBw4EEFBQWbtbGxs4OnpKT7c3NwaY3eokSkVciz7R0+42qsAALsTsrF0V5LEVRERkaWTNADp9XrEx8cjPDxcXCaXyxEeHo4DBw5Uu86WLVsQGhqKyMhI6HQ6dO3aFdHR0TAYDGbtLl68CG9vb7Rp0wajR49GSkrKPesoLy9HQUGB2YOaDk+tBh8/0wMymen1v3ckYse5TGmLIiIiiyZpAMrJyYHBYIBOpzNbrtPpkJGRUe06ycnJWL9+PQwGA2JiYjB37lwsXrwY77//vtgmJCQEq1evxrZt27B8+XJcvnwZAwYMQGFhYbXbXLBgAbRarfjw9fWtv52kRtG/vRteHxwAABAEYOq6E7iYWf3vm4iISPIusJoyGo3w8PDAypUrERwcjFGjRmHOnDlYsWKF2ObRRx/FyJEjERgYiIiICMTExCAvLw/ff/99tducPXs28vPzxUdqampj7Q7Vo8iH22FoNy8AQFF5JSZ8dRR5JRwUTUREVUkagNzc3KBQKJCZad5dkZmZCU9Pz2rX8fLyQkBAABQKhbisU6dOyMjIgF5f/Zeds7MzAgICkJRU/dgQtVoNJycnswc1PTKZDItGBqKzl+n3d/VGCSb/7zgqDUaJKyMiIksjaQBSqVQIDg5GXFycuMxoNCIuLg6hoaHVrhMWFoakpCQYjXe+1BITE+Hl5QWVSlXtOkVFRbh06RK8vLzqdwfI4tipbLByTLA4KHrvxRws+OWCxFUREZGlkbwLbPr06Vi1ahXWrFmD8+fPY9KkSSguLsb48eMBAGPGjMHs2bPF9pMmTUJubi6ioqKQmJiIrVu3Ijo6GpGRkWKbN954A3v27MGVK1fw+++/429/+xsUCgWeffbZRt8/anwtXeyw/Llg2MhNo6I/33cZ3x9ltyYREd1hI3UBo0aNQnZ2NubNm4eMjAx0794d27ZtEwdGp6SkQC6/k9N8fX0RGxuLadOmITAwED4+PoiKisLMmTPFNteuXcOzzz6LGzduwN3dHf3798fBgwfh7u7e6PtH0ujTugXeGd4FczaeAQD834bT8HG2RVg7TodARESATOBdJKsoKCiAVqtFfn4+xwM1cfM3n8GaA6b7hDlqbPDjpH4I0DlKXBURETWEmnx/S94FRtSQ5g3rgvBOHgCAwrJKjP/yCLIKyySuioiIpMYARM2aQi7DJ8/2QDcfLQDT7TJeXH0UJfpKiSsjIiIpMQBRs2enssHnY3vBx9kWAHA6LR9T/nccBt4zjIjIajEAkVXwcNLgy/G94ag2jfvfcT4LczefAYfAERFZJwYgshoBOkeseP7O5fHfHUrBR9sTJa6KiIikwABEViWsnRsWPx0k3jj1051J+HzfZWmLIiKiRscARFZneHcfvD2si/j6vZ/PYcOxaxJWREREjY0BiKzS2H7+iBrUXnw9Y/0p7LyQeZ81iIioOWEAIqs1Nbw9xoS2AgAYjAImfXMMB5NvSFwVERE1BgYgsloymQxvD+uCJ4K8AQDllUa8sPoIjl7JlbgyIiJqaAxAZNXkchn+NTIIf+1omi26RG/AuC+P4FjKTYkrIyKihsQARFZPZSPHf0b3xID2phulFpVXYuznh3HqWp60hRERUYNhACICoFEqsGpML4S1cwUAFJZX4rn/HsKZtHyJKyMioobAAER0i0apwH/H9EZI6xYAgIKySjz/+SGcu14gcWVERFTfGICI7mKrUuCLcb3Rq5ULAOBmSQWeXXUQJ1LzpC2MiIjqFQMQ0R/Yq23w5fje6OnnDADIL63Ac/89hCO8OoyIqNlgACKqhqNGia9fDEHfNqbusKLySoz5/DD2XcyRuDIiIqoPDEBE92CvtsHq8X0wMMAdAFBaYcALa45wxmgiomaAAYjoPjRKBVaOCcYjnXUAAH2lES99FY+fT12XuDIiIqoLBiCiP6G2UWDZ6J4YdmvG6EqjgMn/O441v1+RtjAiIqo1BiCiB6BUyLFkVHeM6uULABAEYP6Ws1gUewGCIEhcHRER1RQDENEDUshlWDiiG157uJ24bNmuS3hz/SlUGowSVkZERDXFAERUAzKZDG9EdMA7T3SBTGZa9kP8Nbz0dTxK9QZpiyMiogfGAERUC2P7+WPpsz2hUpj+Cu28kIVnVh1EdmG5xJUREdGDYAAiqqWhgV5Y/UJvOKptAAAnU/Pw5LL9uJDBW2cQEVk6BiCiOujX1g3rXg6Fl1YDAEjLK8Xflx/ArgtZEldGRET3wwBEVEedvZ2wOTIMgS21AEyzRr+45ghW778scWVERHQvDEBE9cDDSYN1L4Xi0a6eAACjALz90znM23yGV4gREVkgBiCiemKrUmDZP3oi8uG24rKvDlzFc58fQk4RB0cTEVkSBiCieiSXyzAjoiMWjwyCUmG6Tv5gci6e+HQfTqbmSVscERGJGICIGsCI4JZY+1IoPBzVAIDr+WUY+dkBfH80VeLKiIgIYAAiajDBrVzw8+T+6NXKBYDpRqpvrj+FuZvOQF/JcUFERFJiACJqQB5OGnw3sS/GhLYSl3198CqeWXkAaXmlElZGRGTdGICIGpjKRo53h3fFor8HQmVj+it3LCUPj328F9vPZUpcHRGRdWIAImokI3v5Yv0roWjpYgsAyC+twMSvjuK9n8+xS4yIqJExABE1osCWztg6ZQCGdPEUl32+7zJGrvgdqbklElZGRGRdGICIGpnWVonlz/XEO090EW+mevJaPh77ZC9+PnVd4uqIiKwDAxCRBGQyGcb288eGV/uhlasdAKCwrBKvfXcc09adQH5phcQVEhE1bwxARBLq6qPFz5P7Y1iQt7hs4/E0PLrkNxy4dEPCyoiImjcGICKJOWqU+OSZ7lgyqjscNTYATBMn/uO/B/HB1nMorzRIXCERUfNjEQFo2bJl8Pf3h0ajQUhICA4fPnzf9nl5eYiMjISXlxfUajUCAgIQExNTbduFCxdCJpNh6tSpDVA5Uf2QyWR4socPtk19CH3btAAACAKwau9lDF+6H2fS8iWukIioeZE8AK1btw7Tp0/H/PnzcezYMQQFBSEiIgJZWVnVttfr9Rg8eDCuXLmC9evXIyEhAatWrYKPj0+VtkeOHMFnn32GwMDAht4Nonrh42yL7yb0xZzHOokDpC9kFGL4sv1YFHsBZRU8G0REVB8kD0AfffQRJk6ciPHjx6Nz585YsWIF7Ozs8MUXX1Tb/osvvkBubi42bdqEsLAw+Pv7Y+DAgQgKCjJrV1RUhNGjR2PVqlVwcXG5bw3l5eUoKCgwexBJRS6XYeJDbbBlchg6ejoCAAxGAct2XcLQT/Yi/upNiSskImr6JA1Aer0e8fHxCA8PF5fJ5XKEh4fjwIED1a6zZcsWhIaGIjIyEjqdDl27dkV0dDQMBvP/GUdGRmLo0KFm276XBQsWQKvVig9fX9+67RhRPejo6YQtr/VH1KD24p3lL2UX4+8rfsc7P51Fib5S4gqJiJouSQNQTk4ODAYDdDqd2XKdToeMjIxq10lOTsb69ethMBgQExODuXPnYvHixXj//ffFNmvXrsWxY8ewYMGCB6pj9uzZyM/PFx+pqbxjN1kGlY0c0wYH4KfJ/RHYUgvANDboy/1XELHkN/yWmC1xhURETZON1AXUlNFohIeHB1auXAmFQoHg4GCkpaVh0aJFmD9/PlJTUxEVFYXt27dDo9E80DbVajXUanUDV05Uex09nbBhUj98vu8yPtqeiPJKI1JzSzHmi8MYGuiFuUM7w1P7YH/eiYhI4jNAbm5uUCgUyMw0vyFkZmYmPD09q13Hy8sLAQEBUCgU4rJOnTohIyND7FLLyspCz549YWNjAxsbG+zZsweffPIJbGxsqnSVETUVNgo5Xh7YFr9EDUCf1i3E5VtPpWPQ4t34795kVBp4TzEiogchaQBSqVQIDg5GXFycuMxoNCIuLg6hoaHVrhMWFoakpCQYjXf+oU9MTISXlxdUKhUGDRqE06dP48SJE+KjV69eGD16NE6cOGEWnIiaojbuDlg7sS8W/T0QLexVAIBivQHvbz2Pxz/dh/iruRJXSERk+SS/Cmz69OlYtWoV1qxZg/Pnz2PSpEkoLi7G+PHjAQBjxozB7NmzxfaTJk1Cbm4uoqKikJiYiK1btyI6OhqRkZEAAEdHR3Tt2tXsYW9vD1dXV3Tt2lWSfSSqb3K5DCN7+WLn6wPxbB8/yExjpHEhoxAjlh/AjB9OIquwTNoiiYgsmORjgEaNGoXs7GzMmzcPGRkZ6N69O7Zt2yYOjE5JSYFcfien+fr6IjY2FtOmTUNgYCB8fHwQFRWFmTNnSrULRJJxtlNhwVPdMLJXS8zddAZnr5umcPgh/hpiTqfj1Yfb4cX+raFR8swnEdHdZIIgCFIXYWkKCgqg1WqRn58PJycnqcsheiCVBiO+OXgVi7cnorDsziXyPs62+L/HOuGxbp6Q3T5VRETUDNXk+5sBqBoMQNSU5Rbr8e/tifj20FUY7/rb3dvfBXMf74zAls6S1UZE1JAYgOqIAYiag4SMQry/9Rz2XswxW/5EkDemDw6Av5u9RJURETUMBqA6YgCi5kIQBOxKyML7P59Hck6xuNxGLsMzfXwx5a/t4eHE+YOIqHlgAKojBiBqbvSVRnx76Co+3ZmE3GK9uFyjlOOFsNZ4eWBbaG2VElZIRFR3DEB1xABEzVVReSX+uzcZq35LRrH+zqSgWlslXh7YBmND/WGvlvziUCKiWmEAqiMGIGrubhSVY9muS/jm4FXo75o92sVOiQkD2mBsP384MAgRURPDAFRHDEBkLa7dLMGSHRex4dg1syvGnO2UmNC/Ncb284ejhl1jRNQ0MADVEQMQWZukrCIs3XkRW05eNwtCWlslXuzfGuPC/OHEIEREFo4BqI4YgMhaJWcXYemuJGw6nmYWhBzVNvhHXz+8ENYaOl41RkQWigGojhiAyNpdySnG0l1J2Hg8DYa7kpBSIcPfevjgpYfaoJ2Ho4QVEhFVxQBURwxARCZXbxRjxZ5L+DE+zWywNACEd9LhlYFt0Mu/hUTVERGZYwCqIwYgInNZBWVY/fsVfH3wqtl9xgCgp58zxoe1xpCunlAq5PfYAhFRw2MAqiMGIKLqFZVXYu3hFPx372VkFJSZvadzUuO5kFZ4NsQPbg5qiSokImvGAFRHDEBE96evNOKnk9ex8rdkJGQWmr2nUsgxLMgb4/r5o1tLrUQVEpE1YgCqIwYgogcjCAIOXLqBL3+/gh3nM/HHf02CW7ng+b6tMKSrJzRKhTRFEpHVYACqIwYgoppLzS3B1wevYu3hFBT8YZyQs50ST/VoiWf7+KK9jlePEVHDYACqIwYgotor0Vdi4/E0rPn9ChIzi6q839vfBc/09sPQQC+eFSKiesUAVEcMQER1JwgCDl3OxdrDKYg5kwF9pfll9E4aGzzVsyX+HtwSXbydIJPJJKqUiJoLBqA6YgAiql95JXpsOJaG7w6nICmr6lmhDjpHjAj2wZPdfeDBmaaJqJYYgOqIAYioYQiCgPirN/Hd4RRsPZWO8j+cFZLLgAHt3fFUTx880tkTtip2kRHRg2MAqiMGIKKGl19SgZ9OXceGY9dwLCWvyvsOahsM7eaF4T28EdLaFQo5u8iI6P4YgOqIAYiocV3OKcaGY9ew4Vga0vJKq7zv7qjGY1098XiQN4L9XCBnGCKiajAA1REDEJE0jEYBh6/kYsOxa4g5nYGi8soqbby0GjzWzQvDgrwR1FLLwdNEJGIAqiMGICLpleoN2HE+Ez+fuo5dCdlVriIDAN8WthjazRtDunoi0EfLM0NEVo4BqI4YgIgsS2FZBbafy8TPp9Kx92I2KgxV/9nSOakxuLMOEV080beNK2/MSmSFGIDqiAGIyHLll1Qg9mwGfjp1Hb9fugGDseo/YY4aGwzq6IFHunhiYIA77NU2ElRKRI2NAaiOGICImoYbReXYcT4TsWczsS8pp9puMpWNHAPaueHhjh54uKMHfJxtJaiUiBoDA1AdMQARNT1F5ZXYk5CNX89lYOeFLBSWVR1ADZgmXfxLR3f8JcADvfxd2FVG1IwwANURAxBR06avNOJg8g38ei4Dv57NRFZhebXtHNU2GBDghr908MBfAtw5CzVRE8cAVEcMQETNh9Eo4Oz1AuxKyMKuhCycSM3Dvf7V6+TlhP7tXBHWzg19WreAnYpjh4iaEgagOmIAImq+cov1+C0xG7sSsrAnMRt5JRXVtlMp5OjZyhn927khrJ0buvloYcPuMiKLxgBURwxARNbBYBRwIjUPuxOysDshG2eu59/z7JCjxgahbVzRv70b+rV1RVt3B07CSGRhGIDqiAGIyDrdLNbjQPIN7EvKwf6kHFy9UXLPtq72KvRp3QJ9WrdASGtXdPR05ESMRBJjAKojBiAiAoDU3BLsS8rBvqQc/J6Ug5v36C4DACeNjVkg6uLtxC4zokbGAFRHDEBE9EdGo4Bz6QXYn5SDw5dzcfhK7j0vtQcAe5UCPVu5ILiVC3r6uaC7nzOcNMpGrJjI+jAA1REDEBH9GYNRwIWMAhxKzhUDUW6x/p7tZTIgwMMRPVs5o4efKRS1cbNntxlRPWIAqiMGICKqKUEQkJRVhEOXc02P5Bv3nH/oNq2tEj38nNHzViDq1lILrS3PEhHVFgNQHTEAEVFdCYKAazdLcSzlJo5dvYn4lJs4n15Y7b3L7tbazR7dfLQIbKlFYEtndPF24r3MiB4QA1AdMQARUUMo0Vfi1LV8MRQdS8m7b7cZYOo6a+fugG4ttQhq6YxuLbXo7OUEjVLRSFUTNR1NLgAtW7YMixYtQkZGBoKCgvDpp5+iT58+92yfl5eHOXPmYMOGDcjNzUWrVq2wZMkSPPbYYwCA5cuXY/ny5bhy5QoAoEuXLpg3bx4effTRB6qHAYiIGoMgCLh6owTHUm7ieEoeTqfl41x6QbU3db2bQi5Dew8HdPHWopOXIzp7O6GzlxOc7VSNVDmRZarJ97fk51XXrVuH6dOnY8WKFQgJCcGSJUsQERGBhIQEeHh4VGmv1+sxePBgeHh4YP369fDx8cHVq1fh7OwstmnZsiUWLlyI9u3bQxAErFmzBsOHD8fx48fRpUuXRtw7IqJ7k8lk8Hezh7+bPZ7q2RKA6T5miZmFOJ2Wj1PX8nE6LQ8X0gtReVfXmWkAdiEuZBSabc9bqxHDUCcvJ3T2doKvix0HWhNVQ/IzQCEhIejduzeWLl0KADAajfD19cXkyZMxa9asKu1XrFiBRYsW4cKFC1AqH3ywYIsWLbBo0SK8+OKLVd4rLy9HefmdwYoFBQXw9fXlGSAisghlFQZcyCjE6Wt5OHXNFIySsov+dDwRYLoc/3YY6uDpiACdIwI8HKG142Bran6aTBeYXq+HnZ0d1q9fjyeffFJcPnbsWOTl5WHz5s1V1nnsscfQokUL2NnZYfPmzXB3d8c//vEPzJw5EwpF1T5xg8GAH374AWPHjsXx48fRuXPnKm3efvttvPPOO1WWMwARkaUqqzAgMbMQ59MLcO56Ac6nF+JcegGKyu89N9HddE5qBOgc0d7DEQE6BwR4OqK9hwMcOVcRNWFNpgssJycHBoMBOp3ObLlOp8OFCxeqXSc5ORk7d+7E6NGjERMTg6SkJLz66quoqKjA/PnzxXanT59GaGgoysrK4ODggI0bN1YbfgBg9uzZmD59uvj69hkgIiJLpVEqENjSGYEtncVlRqPpyrNz6QU4l14ghqO0vNIq62cWlCOzoBx7L+aYLffWatBe54gOtwJRgM4RbdztGYyo2ZF8DFBNGY1GeHh4YOXKlVAoFAgODkZaWhoWLVpkFoA6dOiAEydOID8/H+vXr8fYsWOxZ8+eakOQWq2GWq1uzN0gIqp3crkMfq528HO1w5CunuLy/JIKnM8oQGJm4a1HERIzC5FXza09rueX4Xp+GfYkZpstd3dUo42bPdq4O6Ctuz3aujugjbs9WrrYQcExRtQESRqA3NzcoFAokJmZabY8MzMTnp6e1a7j5eUFpVJp1t3VqVMnZGRkQK/XQ6UyXQWhUqnQrl07AEBwcDCOHDmCjz/+GJ999lkD7Q0RkWXS2inRt40r+rZxFZcJgoDsonJcvBWGEsWfhdXe4iO7sBzZheU4dDnXbLlKIUcrVzu0cTeFozZu9mjr4YC2bg4cZ0QWTdIApFKpEBwcjLi4OHEMkNFoRFxcHF577bVq1wkLC8N3330Ho9EIudx0o8HExER4eXmJ4ac6RqPRbKAzEZE1k8lk8HDUwMNRg7B2buJyQRCQWVAuhqGkrCIkZxcjOacIOUVV5yzSG4y4mFWEi1lFAMz/M+tip4Sfqz1atbCDv6sd/Fztb/20g7uDGjIZzxyRdCTvAps+fTrGjh2LXr16oU+fPliyZAmKi4sxfvx4AMCYMWPg4+ODBQsWAAAmTZqEpUuXIioqCpMnT8bFixcRHR2NKVOmiNucPXs2Hn30Ufj5+aGwsBDfffcddu/ejdjYWEn2kYioqZDJZPDUauCp1eChAHez9/JLKnAp51Ygyr4TjK7klEBvqDp30c2SCtwsycPJ1Lwq79mpFPBrYYdWrnbwd7WHn6sdWrWwRytXO3g727JbjRqc5AFo1KhRyM7Oxrx585CRkYHu3btj27Zt4sDolJQU8UwPAPj6+iI2NhbTpk1DYGAgfHx8EBUVhZkzZ4ptsrKyMGbMGKSnp0Or1SIwMBCxsbEYPHhwo+8fEVFzobVTivctu5vBKCDtZikuZRfhUnYRknNMASnlRgnSC8pQ3bXGJXpDtXMZAYBSIUNLFzu0dLG99TB/7u6g5txGVGeSzwNkiTgTNBFR/SirMODazRJcvVGCKzdKkHKj2PQztwSpuSVmEzw+KJVCDm9nzT1Ckh08HBmQrFWTuQyeiIiaN41SgXYejmjn4VjlvUqDEen5Zbh6owRXc4tNP2+YfqbmlqBYb6h2m3qDEVduBarq3A5I3s628NRq4K21hZezBl5aDby0tvDW2sLJ1oZjkKwcAxAREUnCRiGHbws7+LawQ3+4mb0nCALySipw7WYprt0sQVpeqfj82s3SOgUkwDQGSQxH2lvhyNlWDElezho4ce6jZo0BiIiILI5MJoOLvQou9ip0a6mt8r4gCMgvrTALRX98fr9ZsUv0hluDuYvv2cZBbQPPW+HI3VENnZMGuls/PZw08HBUw8NJDbVN1bsQkOVjACIioiZHJpPB2U4FZzsVuvpUDUgAUFBWgYz8MlzPK0V6fhnSb//ML8P1/FKk55WhtKL6s0gAUFReiaSsIiRlFd23Fhc7JXROd4Ukp1shyVENDyeN6T0HNVQ28vtuhxoXAxARETVLTholnDRKBOiqjj8CTGeRCkorcT2/1BSUboUiU0gyhaXreaUor6x6if/dTJf7V1R7RdvdXO1VcHdUw91RDTcHNdwcVLd+quHmaHrt7qBGC3sVbBQMSw2NAYiIiKySTCaD1k4JrZ0Snbyqv2LodkjKKiy7df+0MmQWliGroFxcdvun/k+C0o1iPW4U6/80KMlkgIudyjwgOajh5mh67X7Xa1d7nlmqLQYgIiKie7g7JLW/x5kk4M6YpLsDUWZBGbILb4WmAtOy7MLyaieNNN8WkFusR26xHomZ9+9+AwCtrRKuDiq0sFOhhf2fP+xU/OoHGICIiIjq7O4xSR087x+UCsoqkVNUjpzCcuQU6U3Pbz2yC8uRXaS/9V75n3a/AUB+aQXySyuQjHsP6L6bRimHq70aLvZKtLBXo4XdrZ+3X/8hMDnbKpvlvEoMQERERI1EJpNBa6uE1laJtu4O920rCAKKyivvhKRboSj7D69zikxni+531dvdyiqMSMsrRVpe6QPWbDrL5GKnuvVTeSvsKeFsq4KLvVJ839nuVjs7JRzVlj3XEgMQERGRBZLJZHDUKOGoUaK1m/2fti+rMCCvpAI3istxs/j2T1M4ulGsx80SPW4UmX7mFutxs6QChgeYiVsQgLySCuSVVNSofoVcBmdbU/ehi53pTJKzGJKU0NqpMDK4JTRKaaYRYAAiIiJqBjRKBTy1pgkeH4TRKKCgrEIcb5R7d1i6/fpWWDIFID0Kyh7sLBNgukfc7YHfuEf33Mjglg+8vfrGAERERGSF5PI745bauD/YOpUGIwrKKnGzxBSK8kv1uFlcgbxSU0DKK6nAzRI98ksrxDZ5JRXVds/ZKhWSnf0BGICIiIjoAdko5OLg6JqoMBjvBKZboajsPpNQNgYGICIiImpQSoVcnATSUnD2JCIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8MARERERFaHAYiIiIisDgMQERERWR0GICIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8O7wVdDEAQAQEFBgcSVEBER0YO6/b19+3v8fhiAqlFYWAgA8PX1lbgSIiIiqqnCwkJotdr7tpEJDxKTrIzRaMT169fh6OgImUxWr9suKCiAr68vUlNT4eTkVK/bpjt4nBsHj3Pj4HFuHDzOjaehjrUgCCgsLIS3tzfk8vuP8uEZoGrI5XK0bNmyQT/DycmJf8EaAY9z4+Bxbhw8zo2Dx7nxNMSx/rMzP7dxEDQRERFZHQYgIiIisjoMQI1MrVZj/vz5UKvVUpfSrPE4Nw4e58bB49w4eJwbjyUcaw6CJiIiIqvDM0BERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8MA1IiWLVsGf39/aDQahISE4PDhw1KXZLEWLFiA3r17w9HRER4eHnjyySeRkJBg1qasrAyRkZFwdXWFg4MDRowYgczMTLM2KSkpGDp0KOzs7ODh4YEZM2agsrLSrM3u3bvRs2dPqNVqtGvXDqtXr27o3bNYCxcuhEwmw9SpU8VlPM71Jy0tDc899xxcXV1ha2uLbt264ejRo+L7giBg3rx58PLygq2tLcLDw3Hx4kWzbeTm5mL06NFwcnKCs7MzXnzxRRQVFZm1OXXqFAYMGACNRgNfX198+OGHjbJ/lsBgMGDu3Llo3bo1bG1t0bZtW7z33ntm94bica653377DcOGDYO3tzdkMhk2bdpk9n5jHtMffvgBHTt2hEajQbdu3RATE1O7nRKoUaxdu1ZQqVTCF198IZw9e1aYOHGi4OzsLGRmZkpdmkWKiIgQvvzyS+HMmTPCiRMnhMcee0zw8/MTioqKxDavvPKK4OvrK8TFxQlHjx4V+vbtK/Tr1098v7KyUujatasQHh4uHD9+XIiJiRHc3NyE2bNni22Sk5MFOzs7Yfr06cK5c+eETz/9VFAoFMK2bdsadX8tweHDhwV/f38hMDBQiIqKEpfzONeP3NxcoVWrVsK4ceOEQ4cOCcnJyUJsbKyQlJQktlm4cKGg1WqFTZs2CSdPnhSeeOIJoXXr1kJpaanYZsiQIUJQUJBw8OBBYe/evUK7du2EZ599Vnw/Pz9f0Ol0wujRo4UzZ84I//vf/wRbW1vhs88+a9T9lcoHH3wguLq6Cj///LNw+fJl4YcffhAcHByEjz/+WGzD41xzMTExwpw5c4QNGzYIAISNGzeavd9Yx3T//v2CQqEQPvzwQ+HcuXPCW2+9JSiVSuH06dM13icGoEbSp08fITIyUnxtMBgEb29vYcGCBRJW1XRkZWUJAIQ9e/YIgiAIeXl5glKpFH744Qexzfnz5wUAwoEDBwRBMP2FlcvlQkZGhthm+fLlgpOTk1BeXi4IgiC8+eabQpcuXcw+a9SoUUJERERD75JFKSwsFNq3by9s375dGDhwoBiAeJzrz8yZM4X+/fvf832j0Sh4enoKixYtEpfl5eUJarVa+N///icIgiCcO3dOACAcOXJEbPPLL78IMplMSEtLEwRBEP7zn/8ILi4u4rG//dkdOnSo712ySEOHDhVeeOEFs2VPPfWUMHr0aEEQeJzrwx8DUGMe06effloYOnSoWT0hISHCyy+/XOP9YBdYI9Dr9YiPj0d4eLi4TC6XIzw8HAcOHJCwsqYjPz8fANCiRQsAQHx8PCoqKsyOaceOHeHn5yce0wMHDqBbt27Q6XRim4iICBQUFODs2bNim7u3cbuNtf1eIiMjMXTo0CrHgse5/mzZsgW9evXCyJEj4eHhgR49emDVqlXi+5cvX0ZGRobZcdJqtQgJCTE71s7OzujVq5fYJjw8HHK5HIcOHRLbPPTQQ1CpVGKbiIgIJCQk4ObNmw29m5Lr168f4uLikJiYCAA4efIk9u3bh0cffRQAj3NDaMxjWp//ljAANYKcnBwYDAazLwgA0Ol0yMjIkKiqpsNoNGLq1KkICwtD165dAQAZGRlQqVRwdnY2a3v3Mc3IyKj2mN9+735tCgoKUFpa2hC7Y3HWrl2LY8eOYcGCBVXe43GuP8nJyVi+fDnat2+P2NhYTJo0CVOmTMGaNWsA3DlW9/t3IiMjAx4eHmbv29jYoEWLFjX6fTRns2bNwjPPPIOOHTtCqVSiR48emDp1KkaPHg2Ax7khNOYxvVeb2hxz3g2eLF5kZCTOnDmDffv2SV1Ks5OamoqoqChs374dGo1G6nKaNaPRiF69eiE6OhoA0KNHD5w5cwYrVqzA2LFjJa6u+fj+++/x7bff4rvvvkOXLl1w4sQJTJ06Fd7e3jzOZIZngBqBm5sbFApFlStnMjMz4enpKVFVTcNrr72Gn3/+Gbt27ULLli3F5Z6entDr9cjLyzNrf/cx9fT0rPaY337vfm2cnJxga2tb37tjceLj45GVlYWePXvCxsYGNjY22LNnDz755BPY2NhAp9PxONcTLy8vdO7c2WxZp06dkJKSAuDOsbrfvxOenp7Iysoye7+yshK5ubk1+n00ZzNmzBDPAnXr1g3PP/88pk2bJp7h5HGuf415TO/VpjbHnAGoEahUKgQHByMuLk5cZjQaERcXh9DQUAkrs1yCIOC1117Dxo0bsXPnTrRu3drs/eDgYCiVSrNjmpCQgJSUFPGYhoaG4vTp02Z/6bZv3w4nJyfxiyg0NNRsG7fbWMvvZdCgQTh9+jROnDghPnr16oXRo0eLz3mc60dYWFiVqRwSExPRqlUrAEDr1q3h6elpdpwKCgpw6NAhs2Odl5eH+Ph4sc3OnTthNBoREhIitvntt99QUVEhttm+fTs6dOgAFxeXBts/S1FSUgK53PyrTaFQwGg0AuBxbgiNeUzr9d+SGg+bplpZu3atoFarhdWrVwvnzp0TXnrpJcHZ2dnsyhm6Y9KkSYJWqxV2794tpKeni4+SkhKxzSuvvCL4+fkJO3fuFI4ePSqEhoYKoaGh4vu3L89+5JFHhBMnTgjbtm0T3N3dq708e8aMGcL58+eFZcuWWd3l2X9091VggsDjXF8OHz4s2NjYCB988IFw8eJF4dtvvxXs7OyEb775RmyzcOFCwdnZWdi8ebNw6tQpYfjw4dVeStyjRw/h0KFDwr59+4T27dubXUqcl5cn6HQ64fnnnxfOnDkjrF27VrCzs2u2l2f/0dixYwUfHx/xMvgNGzYIbm5uwptvvim24XGuucLCQuH48ePC8ePHBQDCRx99JBw/fly4evWqIAiNd0z3798v2NjYCP/617+E8+fPC/Pnz+dl8E3Bp59+Kvj5+QkqlUro06ePcPDgQalLslgAqn18+eWXYpvS0lLh1VdfFVxcXAQ7Ozvhb3/7m5Cenm62nStXrgiPPvqoYGtrK7i5uQmvv/66UFFRYdZm165dQvfu3QWVSiW0adPG7DOs0R8DEI9z/fnpp5+Erl27Cmq1WujYsaOwcuVKs/eNRqMwd+5cQafTCWq1Whg0aJCQkJBg1ubGjRvCs88+Kzg4OAhOTk7C+PHjhcLCQrM2J0+eFPr37y+o1WrBx8dHWLhwYYPvm6UoKCgQoqKiBD8/P0Gj0Qht2rQR5syZY3ZpNY9zze3atavaf5PHjh0rCELjHtPvv/9eCAgIEFQqldClSxdh69attdonmSDcNT0mERERkRXgGCAiIiKyOgxAREREZHUYgIiIiMjqMAARERGR1WEAIiIiIqvDAERERERWhwGIiIiIrA4DEJEV2rhxI77//nupyyAikgwDEJGVOXz4MKZOnYq+fftKXUqd7d69GzKZrMrNWmvi7bffRvfu3eutpvo2btw4PPnkk1KXQdTsMAARNWHjxo2DTCbDwoULzZZv2rQJMpmsSvv8/HxMmDABGzduhJ+fX2OVadHeeOMNs5srWlrg+Pjjj7F69WqpyyBqdhiAiJo4jUaDf/7zn7h58+afttVqtTh16hR69uzZCJVVT6/XS/bZ1XFwcICrq2u9b7e+9lOr1cLZ2bletkVEdzAAETVx4eHh8PT0xIIFC+7ZprpuniVLlsDf3198ffvMR3R0NHQ6HZydnfHuu++isrISM2bMQIsWLdCyZUt8+eWXZttJTU3F008/DWdnZ7Ro0QLDhw/HlStXqmz3gw8+gLe3Nzp06AAAOH36NP7617/C1tYWrq6ueOmll1BUVHTffY2JiUFAQABsbW3x8MMPm33Obfv27cOAAQNga2sLX19fTJkyBcXFxQ90bN5++22sWbMGmzdvhkwmg0wmw+7du+u0n19//TV69eoFR0dHeHp64h//+AeysrLMajh79iwef/xxODk5wdHREQMGDMClS5fMtntbeXk5pkyZAg8PD2g0GvTv3x9HjhwR37/dLRgXF4devXrBzs4O/fr1Q0JCgtlnbt68GT179oRGo0GbNm3wzjvvoLKyEgAgCALefvtt+Pn5Qa1Ww9vbG1OmTLnv74aoqWEAImriFAoFoqOj8emnn+LatWt12tbOnTtx/fp1/Pbbb/joo48wf/58PP7443BxccGhQ4fwyiuv4OWXXxY/p6KiAhEREXB0dMTevXuxf/9+ODg4YMiQIWZnQOLi4pCQkIDt27fj559/RnFxMSIiIuDi4oIjR47ghx9+wI4dO/Daa6/ds7bU1FQ89dRTGDZsGE6cOIEJEyZg1qxZZm0uXbqEIUOGYMSIETh16hTWrVuHffv23Xe7d3vjjTfw9NNPY8iQIUhPT0d6ejr69etX6/28fYzee+89nDx5Eps2bcKVK1cwbtw4cZ20tDQ89NBDUKvV2LlzJ+Lj4/HCCy+IYeSP3nzzTfz4449Ys2YNjh07hnbt2iEiIgK5ublm7ebMmYPFixfj6NGjsLGxwQsvvCC+t3fvXowZMwZRUVE4d+4cPvvsM6xevRoffPABAODHH3/Ev//9b3z22We4ePEiNm3ahG7duj3QMSRqMmp1D3kisghjx44Vhg8fLgiCIPTt21d44YUXBEEQhI0bNwp3//WeP3++EBQUZLbuv//9b6FVq1Zm22rVqpVgMBjEZR06dBAGDBggvq6srBTs7e2F//3vf4IgCMLXX38tdOjQQTAajWKb8vJywdbWVoiNjRW3q9PphPLycrHNypUrBRcXF6GoqEhctnXrVkEulwsZGRnV7uvs2bOFzp07my2bOXOmAEC4efOmIAiC8OKLLwovvfSSWZu9e/cKcrlcKC0trXa7fzw2dx/T22q7n9U5cuSIAEAoLCwU96t169aCXq+vtv3d9RQVFQlKpVL49ttvxff1er3g7e0tfPjhh4IgCMKuXbsEAMKOHTvENlu3bhUAiMdg0KBBQnR0dJV99PLyEgRBEBYvXiwEBATcsyai5oBngIiaiX/+859Ys2YNzp8/X+ttdOnSBXL5nX8WdDqd2f/8FQoFXF1dxS6ckydPIikpCY6OjnBwcICDgwNatGiBsrIysQsHALp16waVSiW+Pn/+PIKCgmBvby8uCwsLg9ForNJVc/c6ISEhZstCQ0PNXp88eRKrV68Wa3FwcEBERASMRiMuX75ciyNyZ7u12U8AiI+Px7Bhw+Dn5wdHR0cMHDgQAJCSkgIAOHHiBAYMGAClUvmndVy6dAkVFRUICwsTlymVSvTp06fK7z0wMFB87uXlBQBmv7d3333X7DhNnDgR6enpKCkpwciRI1FaWoo2bdpg4sSJ2Lhx4z3PSBE1VTZSF0BE9eOhhx5CREQEZs+ebdbFAgByuRyCIJgtq6ioqLKNP34Jy2SyapcZjUYAQFFREYKDg/Htt99W2Za7u7v4/O6g05CKiorw8ssvVztepS5XvdV2P2939UVERODbb7+Fu7s7UlJSEBERIXad2dra1rqu+7n793b7isC7f2/vvPMOnnrqqSrraTQa+Pr6IiEhATt27MD27dvx6quvYtGiRdizZ88DBTWipoABiKgZWbhwIbp37y4OwL3N3d0dGRkZEARB/DI8ceJEnT+vZ8+eWLduHTw8PODk5PTA63Xq1AmrV69GcXGxGBr2798PuVxepfa719myZYvZsoMHD1ap59y5c2jXrl0N9+QOlUoFg8FQZbu12c8LFy7gxo0bWLhwIXx9fQEAR48eNWsTGBiINWvWoKKi4k/DRdu2baFSqbB//360atUKgCnIHjlyBFOnTn3gunr27ImEhIT7HidbW1sMGzYMw4YNQ2RkJDp27IjTp09LegUhUX1iFxhRM9KtWzeMHj0an3zyidnyv/zlL8jOzsaHH36IS5cuYdmyZfjll1/q/HmjR4+Gm5sbhg8fjr179+Ly5cvYvXs3pkyZct8B2aNHj4ZGo8HYsWNx5swZ7Nq1C5MnT8bzzz8PnU5X7TqvvPIKLl68iBkzZiAhIQHfffddlflxZs6cid9//x2vvfYaTpw4gYsXL2Lz5s0PPAgaAPz9/XHq1CkkJCQgJycHFRUVtd5PPz8/qFQqfPrpp0hOTsaWLVvw3nvvmbV57bXXUFBQgGeeeQZHjx7FxYsX8fXXX1fbFWhvb49JkyZhxowZ2LZtG86dO4eJEyeipKQEL7744gPv47x58/DVV1/hnXfewdmzZ3H+/HmsXbsWb731FgBg9erV+Pzzz3HmzBkkJyfjm2++ga2trRi6iJoDBiCiZubdd98Vuzpu69SpE/7zn/9g2bJlCAoKwuHDh/HGG2/U+bPs7Ozw22+/wc/PD0899RQ6deqEF198EWVlZfc9U2JnZ4fY2Fjk5uaid+/e+Pvf/45BgwZh6dKl91zHz88PP/74IzZt2oSgoCCsWLEC0dHRZm0CAwOxZ88eJCYmYsCAAejRowfmzZsHb2/vB96niRMnokOHDujVqxfc3d2xf//+Wu+nu7s7Vq9ejR9++AGdO3fGwoUL8a9//cusjaurK3bu3ImioiIMHDgQwcHBWLVq1T3PBi1cuBAjRozA888/j549eyIpKQmxsbFwcXF54H2MiIjAzz//jF9//RW9e/dG37598e9//1sMOM7Ozli1ahXCwsIQGBiIHTt24KeffmqQ+ZKIpCIT/jgwgIiIiKiZ4xkgIiIisjoMQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1GICIiIjI6vw/ruUb+KMbiQUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elegir algun valor para alpha (probar varias alternativas)\n",
    "alpha = 0.001\n",
    "num_iters = 10000\n",
    "# lambda_reg = 0.01\n",
    "\n",
    "# Inicializa theta y ejecuta el descenso por el gradiente\n",
    "theta = np.zeros(12)\n",
    "theta, J_history = descensoGradiente(theta, X_train_ready, y_train, alpha, num_iters)\n",
    "\n",
    "# Muestra los resultados del descenso del gradiente\n",
    "print('thetas calculados por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
    "print('=' * 100)\n",
    "\n",
    "#mostramos el ultimo costo, este seria el mejor costo\n",
    "print(f\"Con un costo de: { J_history[-1]} \")\n",
    "print('=' * 100)\n",
    "\n",
    "\n",
    "print(\"GRÁFICA DE LA CONVERGENCIA DEL COSTO\")\n",
    "# Grafica de la convergencia del resultado de los partidos\n",
    "plt.plot(np.arange(len(J_history)), J_history, lw=2)\n",
    "plt.xlabel('Número de iteraciones')\n",
    "plt.ylabel('Resultado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando algunas pruebas de que el equipo gana o no en un partido de local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una persona con los siguientes datos: [1, 17230, 1, 153, 115.0, 120, 80, 3, 3, 0, 0, 1]\n",
      "La persona tiene una probabilidad de que tenga la enfermendad cardiovascular de: 1\n"
     ]
    }
   ],
   "source": [
    "# Realizando algunas pruebas de que el equipo gana o no en un partido de local\n",
    "\n",
    "X_array_reg = [1, 17230, 1,\t153, 115.0,\t120,\t80,\t3,\t3,\t0,\t0,\t1]\n",
    "resuldato = sigmoid(np.dot(X_array_reg, theta))   # Se debe cambiar esto\n",
    "\n",
    "print(f\"Una persona con los siguientes datos: {X_array_reg}\")\n",
    "print('La persona tiene una probabilidad de que tenga la enfermendad cardiovascular de: {:.0f}'.format(resuldato))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos hacer predicciones con varios ejemplos, en este caso 14 ejemplos donde se harán la\n",
    "# predicciones correspondientes\n",
    "\n",
    "X_columnas = ['age', 'gender',\t'height', 'weight',\t'ap_hi'\t,'ap_lo',\t'cholesterol',\t'gluc',\t'smoke',\t'alco',\t'active', 'cardio',\t'cardio(Si/No)']\n",
    "\n",
    "matriz_datos = np.array([\n",
    "    [20305,\t2,\t159,\t58.0,\t160,\t90,\t1,\t1,\t1,\t1,\t1],\n",
    "    [21721,\t1,\t160,\t98.0,\t120,\t80,\t1,\t1,\t0,\t0,\t1],\n",
    "    [19998,\t1,\t168,\t76.0,\t160,\t80,\t1,\t1,\t0,\t0,\t1],\n",
    "    [21711,\t1,\t157,\t98.0,\t130,\t90,\t1,\t1,\t0,\t0,\t1],\n",
    "    [18309,\t1,\t163,\t108.0,\t150,\t90,\t1,\t1,\t0,\t0,\t1],\n",
    "    [15353,\t1,\t169,\t67.0,\t120,\t70,\t1,\t1,\t0,\t0,\t1],\n",
    "    [18895,\t2,\t178,\t88.0,\t140,\t80,\t3,\t3,\t0,\t0,\t1],\n",
    "    [19906,\t1,\t170,\t70.0,\t120,\t80,\t1,\t1,\t0,\t0,\t1],\n",
    "    [22031,\t1,\t159,\t71.0,\t160,\t100,1,\t1,\t0,\t0,\t1],\n",
    "    [20426,\t1,\t152,\t78.0,\t120,\t80,\t1,\t1,\t0,\t0,\t1],\n",
    "    [15458,\t1,\t143,\t63.0,\t120,\t80,\t1,\t1,\t0,\t0,\t1]\n",
    "])\n",
    "\n",
    "datos_tabla = matriz_datos.copy()\n",
    "\n",
    "# Creamos el vector para guardar cada Y predicha\n",
    "y_pred = []\n",
    "\n",
    "matriz_datos = (matriz_datos - mu.values) / sigma.values\n",
    "matriz_datos = np.concatenate([np.ones((len(matriz_datos), 1)), matriz_datos], axis=1)\n",
    "\n",
    "# Calculamos la Y predicha de los 14 ejemplos a predecir\n",
    "# Calculamos la Y predicha de cada fila de la matriz_datos\n",
    "for i in matriz_datos:\n",
    "  y_pred.append(sigmoid(np.dot(i, theta)))  #X.dot(theta.T)\n",
    "\n",
    "\n",
    "# Convertimos la lista a un array unidimensional\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Verificamos con el umbral para definir si el Equipo de la BNA gana o no el partido de local\n",
    "y_pred_umbral = (y_pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>cardio(Si/No)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20305.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.370771</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661964</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19998.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479771</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21711.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18309.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15353.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18895.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725386</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22031.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20426.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520729</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15458.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   20305.0     2.0   159.0    58.0  160.0   90.0          1.0   1.0    1.0   \n",
       "1   21721.0     1.0   160.0    98.0  120.0   80.0          1.0   1.0    0.0   \n",
       "2   19998.0     1.0   168.0    76.0  160.0   80.0          1.0   1.0    0.0   \n",
       "3   21711.0     1.0   157.0    98.0  130.0   90.0          1.0   1.0    0.0   \n",
       "4   18309.0     1.0   163.0   108.0  150.0   90.0          1.0   1.0    0.0   \n",
       "5   15353.0     1.0   169.0    67.0  120.0   70.0          1.0   1.0    0.0   \n",
       "6   18895.0     2.0   178.0    88.0  140.0   80.0          3.0   3.0    0.0   \n",
       "7   19906.0     1.0   170.0    70.0  120.0   80.0          1.0   1.0    0.0   \n",
       "8   22031.0     1.0   159.0    71.0  160.0  100.0          1.0   1.0    0.0   \n",
       "9   20426.0     1.0   152.0    78.0  120.0   80.0          1.0   1.0    0.0   \n",
       "10  15458.0     1.0   143.0    63.0  120.0   80.0          1.0   1.0    0.0   \n",
       "\n",
       "    alco  active    cardio  cardio(Si/No)  \n",
       "0    1.0     1.0  0.370771            0.0  \n",
       "1    0.0     1.0  0.661964            1.0  \n",
       "2    0.0     1.0  0.479771            0.0  \n",
       "3    0.0     1.0  0.670891            1.0  \n",
       "4    0.0     1.0  0.590452            1.0  \n",
       "5    0.0     1.0  0.251167            0.0  \n",
       "6    0.0     1.0  0.725386            1.0  \n",
       "7    0.0     1.0  0.428131            0.0  \n",
       "8    0.0     1.0  0.553924            1.0  \n",
       "9    0.0     1.0  0.520729            1.0  \n",
       "10   0.0     1.0  0.271951            0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos la lista a un array unidimensional\n",
    "# y_pred = np.array(y_pred)\n",
    "y_pred_umbral = np.array(y_pred_umbral)\n",
    "\n",
    "# Juntamos los datos de datos_tabla con y_pred y y_pred_umbral en uno solo\n",
    "tabla_predicciones = np.column_stack((datos_tabla, y_pred, y_pred_umbral))\n",
    "tabla_predicciones = pd.DataFrame(tabla_predicciones, columns=X_columnas)\n",
    "\n",
    "# mostramos los datos tabla de datos junto con los y_pred y y_pred_umbral\n",
    "tabla_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validaciones**\n",
    "\n",
    "Para las validaciones correspondientes se hizo el uso del 80% y 20%, donde el 80% son para el entrenamiento y el 20% para la fase de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos con el data de X_test que es el 20$% para la prueba\n",
    "# Normalizamos el X_test\n",
    "X_test_norm = (X_test - mu) / sigma\n",
    "m_test = len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos con la columna de unos (1) al data frame de X_test normalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.38416105  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.         -0.27298772  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.         -0.70527979 -0.7330432  ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " ...\n",
      " [ 1.          0.37565296  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.          0.9063958  -0.7330432  ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.          1.62229092  1.36417608 ... -0.31186032 -0.23863407\n",
      "  -2.0202912 ]]\n"
     ]
    }
   ],
   "source": [
    "X_test_ready = np.concatenate([np.ones((m_test, 1)), X_test_norm], axis=1)\n",
    "\n",
    "# Mostramos los datos del X_test ya normalizados\n",
    "print(X_test_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el cálculo de los resultados de Y predicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13861, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X[:, 0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11] Y_predicha  Y_umbral\n",
      "===========================================================================================================================================================\n",
      "   1.000   0.384     1.364     1.783   0.473  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.502     1.000\n",
      "   1.000  -0.273     1.364     1.052   0.821   0.009  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.476     0.000\n",
      "   1.000  -0.705    -0.733    -0.897  -0.014  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.384     0.000\n",
      "   1.000   1.247    -0.733     4.097   0.404   0.078  -0.035  -0.538 1.354    -0.312    -0.239     0.495     0.553     1.000\n",
      "   1.000  -1.388     1.364     0.687   0.480  -0.060  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.348     0.000\n",
      "   1.000   1.073     1.364    -1.262  -1.266  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.476     0.000\n",
      "   1.000   1.468    -0.733    -0.410  -1.335  -0.198  -0.154   0.934-0.395    -0.312    -0.239    -2.020     0.643     1.000\n",
      "   1.000   0.918    -0.733     0.565  -0.362  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.497     0.000\n",
      "   1.000  -1.122     1.364     0.687  -0.362  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.311     0.000\n",
      "   1.000   0.675     1.364     0.321   0.056   0.078  -0.035  -0.538-0.395     3.207    -0.239    -2.020     0.543     1.000\n",
      "   1.000   0.174     1.364     0.078   0.890   0.078  -0.035  -0.538-0.395     3.207    -0.239    -2.020     0.561     1.000\n",
      "   1.000   0.448    -0.733    -2.115  -0.083   0.009   0.025   2.407-0.395    -0.312    -0.239    -2.020     0.774     1.000\n",
      "   1.000  -1.451    -0.733    -0.166  -1.127  -0.129  -0.154  -0.538-0.395    -0.312    -0.239     0.495     0.236     0.000\n",
      "   1.000   0.314     1.364     1.417   1.308   0.120  -0.165  -0.538 1.354     3.207    -0.239     0.495     0.548     1.000\n",
      "   1.000   1.057    -0.733    -0.531   1.447   0.078  -0.035  -0.538-0.395    -0.312    -0.239    -2.020     0.702     1.000\n",
      "   1.000   0.611    -0.733    -0.410  -0.501  -0.060  -0.154  -0.538-0.395    -0.312    -0.239     0.495     0.466     0.000\n",
      "   1.000   0.916     1.364     2.148   2.003   0.078  -0.035   0.934-0.395     3.207     4.191     0.495     0.732     1.000\n",
      "   1.000   0.602    -0.733    -1.627  -0.501  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.484     0.000\n",
      "   1.000  -2.005    -0.733    -1.749  -0.640  -0.060  -0.035  -0.538-0.395    -0.312    -0.239    -2.020     0.275     0.000\n",
      "   1.000   0.981    -0.733    -0.531   0.612   0.078  -0.094   0.934-0.395    -0.312    -0.239    -2.020     0.744     1.000\n"
     ]
    }
   ],
   "source": [
    "# inicializamos nuestra y_predicha donde almacenaremos nuestras y predichas\n",
    "y_predicha = []\n",
    "\n",
    "# calculamos la Y predicha de cada fila de X_test_ready\n",
    "for i in X_test_ready:\n",
    "  y_predicha.append(sigmoid(np.dot(i, theta)))\n",
    "\n",
    "\n",
    "y_predicha = np.array(y_predicha)\n",
    "\n",
    "# Usando el umbral donde todo valor que sea >= 0.5 sera 1 o al contrario es 0\n",
    "y_umbral = (y_predicha >= 0.5).astype(int)\n",
    "\n",
    "print(\"{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}\".format(\n",
    "    'X[:, 0]','X[:, 1]','X[:, 2]','X[:, 3]','X[:, 4]','X[:, 5]','X[:, 6]','X[:, 7]','X[:, 8]','X[:, 9]',\n",
    "    'X[:, 10]','X[:, 11]', ' Y_predicha', 'Y_umbral'\n",
    "))\n",
    "\n",
    "print(\"=\" * 155)\n",
    "\n",
    "for i in range(20):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:6.3f}{:10.3f}{:10.3f}{:10.3f}{:10.3f}{:10.3f}'.format(\n",
    "        X_test_ready[i, 0], X_test_ready[i, 1], X_test_ready[i, 2], X_test_ready[i, 3], X_test_ready[i, 4], X_test_ready[i, 5], X_test_ready[i, 6],\n",
    "        X_test_ready[i, 7], X_test_ready[i, 8], X_test_ready[i, 9], X_test_ready[i, 10], X_test_ready[i, 11], y_predicha[i], y_umbral[i]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos que tal de precición tiene los datos de entrenamiento\n",
    "\n",
    "Calculamos con el metodo np.mean, la media(promedio) de los valores booleanos. Donde True se considera como 1 y False como 0 en operaciones aritméticas, la media resultante será la proporción de los elementos iguales en y_predicha e y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precición de entrenamiento: 64.90 % \n"
     ]
    }
   ],
   "source": [
    "# Mostramos la precición de entrenamiento\n",
    "print(\"Precición de entrenamiento: {:.2f} % \".format(np.mean(y_umbral == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **- Conclución**\n",
    "\n",
    "Segun los resultados tanto de predicciones y la precición del entranamiento es de un 64.90 % lo que indica que esta por superior a los 50% casi por poco de los 100%.\n",
    "Por lo que podemos decir que el modelo es muy preciso en las predicciones de que una persona con ciertos datos puede tener esa probabilidad de tener la enfermedad de cardiovascular, esto demuestra que la precición mediano por lo que el modelo puede predecir a esa precición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularización Logistica con Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se utiliza para el manejo de rutas y directorios.\n",
    "import os\n",
    "\n",
    "# Calculo cientifico y vectorial para python\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Modulo de optimización de scipy\n",
    "from scipy import optimize\n",
    "\n",
    "#Para separa el Dataset 20% y 80% para diferentes pruebas\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de X_train_reg:\n",
      "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "20241  17230       1     153   115.0    120     80            3     3      0   \n",
      "36773  20257       1     166   103.0    140     90            3     3      0   \n",
      "39989  18885       1     162    91.0    150     90            1     1      0   \n",
      "59583  20306       1     160    62.0    130     90            1     1      0   \n",
      "67792  21987       1     168    72.0    120     80            3     3      0   \n",
      "...      ...     ...     ...     ...    ...    ...          ...   ...    ...   \n",
      "37194  21891       1     155    79.0    120     80            1     1      0   \n",
      "6265   18280       1     155   105.0    120     80            1     1      0   \n",
      "54886  23260       1     158    68.0    130     80            1     1      0   \n",
      "860    17317       2     165    70.0    160     90            1     1      0   \n",
      "15795  16846       1     168    69.0    130     80            1     1      0   \n",
      "\n",
      "       alco  active  \n",
      "20241     0       1  \n",
      "36773     0       1  \n",
      "39989     0       0  \n",
      "59583     0       0  \n",
      "67792     0       0  \n",
      "...     ...     ...  \n",
      "37194     0       1  \n",
      "6265      0       0  \n",
      "54886     0       1  \n",
      "860       0       1  \n",
      "15795     0       1  \n",
      "\n",
      "[55440 rows x 11 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Datos de y_train_reg:\n",
      "20241    1\n",
      "36773    0\n",
      "39989    1\n",
      "59583    0\n",
      "67792    1\n",
      "        ..\n",
      "37194    0\n",
      "6265     0\n",
      "54886    0\n",
      "860      1\n",
      "15795    0\n",
      "Name: cardio, Length: 55440, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "El 80% de ejemplos que seran para el entrenamiento son: 55440\n",
      "El 20% de ejemplos que seran para el entrenamiento son: 13861\n"
     ]
    }
   ],
   "source": [
    "# Leemos los datos del dataset\n",
    "\n",
    "df = data\n",
    "\n",
    "# Aplicando la libreria, separamos los datos del 80% y 20% del Dataset\n",
    "train_data_reg, test_data_reg = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividimos los datos para X_test_reg y y_test_reg donde seran los datos para el prueba \n",
    "X_test_reg = test_data_reg.drop(['cardio'], axis=1)\n",
    "y_test_reg = test_data_reg['cardio']\n",
    "\n",
    "# Dividimos los datos para X_train_reg y y_train_reg donde seran los datos para el entrenamiento\n",
    "X_train_reg = train_data_reg.drop(['cardio'], axis=1)\n",
    "y_train_reg = train_data_reg['cardio']\n",
    "m_train_reg = len(y_train_reg)\n",
    "\n",
    "\n",
    "# Mostramos los datos que seran para el entrenamiento\n",
    "print(\"Datos de X_train_reg:\")\n",
    "print(X_train_reg)\n",
    "print('-' * 100)\n",
    "print(\"Datos de y_train_reg:\")\n",
    "print(y_train_reg)\n",
    "\n",
    "# Mostramos la cantidad de ejemplos que tienen X_train_reg y y_train_reg\n",
    "print('-' * 80)\n",
    "print(\"El 80% de ejemplos que seran para el entrenamiento son: {:.0f}\".format(len(train_data_reg)))\n",
    "print(\"El 20% de ejemplos que seran para el entrenamiento son: {:.0f}\".format(len(test_data_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalización de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la funcion de normalizacion de datos\n",
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "\n",
    "    sigma[sigma == 0] = 1  # verificar\n",
    "\n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>-0.903802</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.383913</td>\n",
       "      <td>2.837900</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>0.322579</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>2.003259</td>\n",
       "      <td>0.078345</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>-0.233283</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.287788</td>\n",
       "      <td>1.168619</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59583</th>\n",
       "      <td>0.342431</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.531371</td>\n",
       "      <td>-0.848427</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67792</th>\n",
       "      <td>1.023483</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.442962</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>2.406517</td>\n",
       "      <td>3.103155</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>0.984589</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.140330</td>\n",
       "      <td>0.333979</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>-0.478397</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-1.140330</td>\n",
       "      <td>2.142366</td>\n",
       "      <td>-0.059603</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>-2.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>1.539236</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>-0.774955</td>\n",
       "      <td>-0.431107</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.868554</td>\n",
       "      <td>1.364176</td>\n",
       "      <td>0.077587</td>\n",
       "      <td>-0.292001</td>\n",
       "      <td>0.216294</td>\n",
       "      <td>-0.034559</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-1.059378</td>\n",
       "      <td>-0.733043</td>\n",
       "      <td>0.442962</td>\n",
       "      <td>-0.361554</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>-0.537897</td>\n",
       "      <td>-0.394815</td>\n",
       "      <td>-0.31186</td>\n",
       "      <td>-0.238634</td>\n",
       "      <td>0.494978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55440 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    gender    height    weight     ap_hi     ap_lo  \\\n",
       "20241 -0.903802 -0.733043 -1.383913  2.837900 -0.059603 -0.094061   \n",
       "36773  0.322579 -0.733043  0.199379  2.003259  0.078345 -0.034559   \n",
       "39989 -0.233283 -0.733043 -0.287788  1.168619  0.147319 -0.034559   \n",
       "59583  0.342431 -0.733043 -0.531371 -0.848427  0.009371 -0.034559   \n",
       "67792  1.023483 -0.733043  0.442962 -0.152894 -0.059603 -0.094061   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "37194  0.984589 -0.733043 -1.140330  0.333979 -0.059603 -0.094061   \n",
       "6265  -0.478397 -0.733043 -1.140330  2.142366 -0.059603 -0.094061   \n",
       "54886  1.539236 -0.733043 -0.774955 -0.431107  0.009371 -0.094061   \n",
       "860   -0.868554  1.364176  0.077587 -0.292001  0.216294 -0.034559   \n",
       "15795 -1.059378 -0.733043  0.442962 -0.361554  0.009371 -0.094061   \n",
       "\n",
       "       cholesterol      gluc    smoke      alco    active  \n",
       "20241     2.406517  3.103155 -0.31186 -0.238634  0.494978  \n",
       "36773     2.406517  3.103155 -0.31186 -0.238634  0.494978  \n",
       "39989    -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "59583    -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "67792     2.406517  3.103155 -0.31186 -0.238634 -2.020291  \n",
       "...            ...       ...      ...       ...       ...  \n",
       "37194    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "6265     -0.537897 -0.394815 -0.31186 -0.238634 -2.020291  \n",
       "54886    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "860      -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "15795    -0.537897 -0.394815 -0.31186 -0.238634  0.494978  \n",
       "\n",
       "[55440 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamamos a la funcion de normalización para normalizar los datos de X_train\n",
    "X_norm_reg, mu_reg, sigma_reg = featureNormalize(X_train_reg)\n",
    "X_norm_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos la columna de unos (1) en X_train para completar los valores para theta 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.90380193, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        ,  0.32257868, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -0.2332833 , -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407, -2.0202912 ],\n",
       "       ...,\n",
       "       [ 1.        ,  1.53923574, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -0.86855412,  1.36417608, ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815],\n",
       "       [ 1.        , -1.05937845, -0.7330432 , ..., -0.31186032,\n",
       "        -0.23863407,  0.49497815]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antes de continuar es importante agregar el termino de intercepcion a X.\n",
    "# Agregamos la columna de 1\n",
    "m_reg, n_reg = X_train_reg.shape\n",
    "\n",
    "# Agraga el termino de intercepción a A\n",
    "X_ready_reg = np.concatenate([np.ones((m_reg, 1)), X_norm_reg], axis=1)\n",
    "\n",
    "# Mostramos los datos\n",
    "X_ready_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 FUNCIÓN SIGMOIDEA\n",
    "\n",
    "La función sigmoidea o tambien llamada función de logistica, nos permite calcaluar o predecir una probabilidad de un hecho que de 0 a 1. Donde z es la transpues de theta por X, que es nuestra hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la función sigmoidea o funcion logistica que calcula la hipotesis ho(x)\n",
    "def sigmoid(z):\n",
    "  # Calcula la sigmoidea de una entrada z\n",
    "  # convierte la entrada a un arreglo numpy\n",
    "  z = np.array(z)\n",
    "  g = np.zeros(z.shape)\n",
    "\n",
    "  g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "  return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 FUNCIÓN DE COSTO Y GRADIENTE\n",
    "\n",
    "Se implementa la funcion cost y gradient, para la regresión logistica, donde hace el uso de la funcion de Sigmoid para calular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo del costo J(θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funcion de costo en una regresión logistica es:\n",
    "def calcularCostoReg(theta, X, y, lambda_reg):\n",
    "  m = y.size # numeros de ejemplos de entrenamiento\n",
    "\n",
    "  J = 0\n",
    "  h = sigmoid(X.dot(theta.T))\n",
    "  \n",
    "  # Término de regularización \n",
    "  theta_reg = theta.copy()\n",
    "  theta_reg[0] = 0  # No regularizar el termino de sesgo\n",
    "\n",
    "  J = - (1 / m) * np.sum(y.dot(np.log(h)) + (1 - y).dot(np.log(1 - h))) + (lambda_reg / (2 * m)) * np.sum(np.square(theta_reg))\n",
    "\n",
    "  return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso por el gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenimos la funcion del Descenso por el gradiente\n",
    "def descensoGradienteReg(theta, X, y, alpha, num_iters, lambda_reg):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    # realizar una copia de theta, el cual será actualizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "        # Actualizar theta_0 (término de sesgo)\n",
    "        theta[0] = theta[0] - (alpha / m) * np.sum((h - y) * X[:, 0])\n",
    "\n",
    "        # Actualizar theta_j (j = 1, 2, ..., n)\n",
    "        for j in range(1, X.shape[1]):\n",
    "            theta[j] = theta[j] - alpha * ((1 / m) * np.sum((h - y) * X[:, j]) + (lambda_reg / m) * theta[j])\n",
    "\n",
    "        J_history.append(calcularCostoReg(theta, X, y, lambda_reg))\n",
    "\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos con algunos alternativas, donde los thetas se inicializan con Cero (0) y con una taza de aprendizaje alpha por lo que hacemos pruebas con diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55440, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ready_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetas calculados por el descenso por el gradiente: [ 0.01588737  0.43289405  0.02564756 -0.07331571  0.34514006  0.33444957\n",
      "  0.22005414  0.39125733 -0.04511437 -0.02678445 -0.03371675 -0.07126973]\n",
      "====================================================================================================\n",
      "Con un costo de: 0.6228494180902806 \n",
      "GRÁFICA DE LA CONVERGENCIA DEL COSTO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Resultado')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elegir algun valor para alpha (probar varias alternativas)\n",
    "alpha_reg = 0.001\n",
    "num_iters = 20000\n",
    "lambda_reg = 0.01\n",
    "\n",
    "# Inicializa theta_reg y ejecuta el descenso por el gradiente\n",
    "theta_reg = np.zeros(12)\n",
    "theta_reg, J_history_reg = descensoGradienteReg(theta_reg, X_ready_reg, y_train_reg, alpha_reg, num_iters, lambda_reg)\n",
    "\n",
    "# Muestra los resultados del descenso del gradiente\n",
    "print('thetas calculados por el descenso por el gradiente: {:s}'.format(str(theta_reg)))\n",
    "print('=' * 100)\n",
    "#mostramos el ultimo costo, este seria el mejor costo\n",
    "print(f\"Con un costo de: { J_history_reg[-1]} \")\n",
    "\n",
    "\n",
    "\n",
    "print(\"GRÁFICA DE LA CONVERGENCIA DEL COSTO\")\n",
    "# Grafica de la convergencia del resultado de los partidos\n",
    "plt.plot(np.arange(len(J_history_reg)), J_history_reg, lw=2)\n",
    "plt.xlabel('Número de iteraciones')\n",
    "plt.ylabel('Resultado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando algunas pruebas de que el equipo gana o no en un partido de local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una persona con los siguientes datos: [1, 17230, 1, 153, 115.0, 120, 80, 3, 3, 0, 0, 1]\n",
      "La persona tiene una probabilidad de que tenga la enfermendad cardiovascular de: 1\n"
     ]
    }
   ],
   "source": [
    "# Realizando algunas pruebas de que el equipo gana o no en un partido de local\n",
    "\n",
    "X_array_reg = [1, 17230, 1,\t153, 115.0,\t120,\t80,\t3,\t3,\t0,\t0,\t1]\n",
    "resuldato = sigmoid(np.dot(X_array_reg, theta_reg))   # Se debe cambiar esto\n",
    "\n",
    "print(f\"Una persona con los siguientes datos: {X_array_reg}\")\n",
    "print('La persona tiene una probabilidad de que tenga la enfermendad cardiovascular de: {:.0f}'.format(resuldato))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaciones con datos de prueba\n",
    "\n",
    "Para las validaciones correspondientes se hizo el uso del 80% y 20%, donde el 80% son para el entrenamiento y el 20% para la fase de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos con el data de X_test que es el 20$% para la prueba\n",
    "# Normalizamos el X_test\n",
    "X_test_norm_reg = (X_test_reg - mu_reg) / sigma_reg\n",
    "m_test = len(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.38416105  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.         -0.27298772  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.         -0.70527979 -0.7330432  ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " ...\n",
      " [ 1.          0.37565296  1.36417608 ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.          0.9063958  -0.7330432  ... -0.31186032 -0.23863407\n",
      "   0.49497815]\n",
      " [ 1.          1.62229092  1.36417608 ... -0.31186032 -0.23863407\n",
      "  -2.0202912 ]]\n"
     ]
    }
   ],
   "source": [
    "X_test_ready_reg = np.concatenate([np.ones((m_test, 1)), X_test_norm_reg], axis=1)\n",
    "\n",
    "# Mostramos los datos del X_test ya normalizados\n",
    "print(X_test_ready_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X[:, 0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11] Y_predicha  Y_umbral    Y_test\n",
      "===============================================================================================================================================================================\n",
      "   1.000   0.384     1.364     1.783   0.473  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.499     0.000     1.000\n",
      "   1.000  -0.273     1.364     1.052   0.821   0.009  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.477     0.000     1.000\n",
      "   1.000  -0.705    -0.733    -0.897  -0.014  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.378     0.000     0.000\n",
      "   1.000   1.247    -0.733     4.097   0.404   0.078  -0.035  -0.538 1.354    -0.312    -0.239     0.495     0.526     1.000     1.000\n",
      "   1.000  -1.388     1.364     0.687   0.480  -0.060  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.338     0.000     1.000\n",
      "   1.000   1.073     1.364    -1.262  -1.266  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.480     0.000     1.000\n",
      "   1.000   1.468    -0.733    -0.410  -1.335  -0.198  -0.154   0.934-0.395    -0.312    -0.239    -2.020     0.656     1.000     0.000\n",
      "   1.000   0.918    -0.733     0.565  -0.362  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.494     0.000     0.000\n",
      "   1.000  -1.122     1.364     0.687  -0.362  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.297     0.000     0.000\n",
      "   1.000   0.675     1.364     0.321   0.056   0.078  -0.035  -0.538-0.395     3.207    -0.239    -2.020     0.557     1.000     1.000\n",
      "   1.000   0.174     1.364     0.078   0.890   0.078  -0.035  -0.538-0.395     3.207    -0.239    -2.020     0.579     1.000     1.000\n",
      "   1.000   0.448    -0.733    -2.115  -0.083   0.009   0.025   2.407-0.395    -0.312    -0.239    -2.020     0.809     1.000     0.000\n",
      "   1.000  -1.451    -0.733    -0.166  -1.127  -0.129  -0.154  -0.538-0.395    -0.312    -0.239     0.495     0.215     0.000     0.000\n",
      "   1.000   0.314     1.364     1.417   1.308   0.120  -0.165  -0.538 1.354     3.207    -0.239     0.495     0.538     1.000     1.000\n",
      "   1.000   1.057    -0.733    -0.531   1.447   0.078  -0.035  -0.538-0.395    -0.312    -0.239    -2.020     0.727     1.000     1.000\n",
      "   1.000   0.611    -0.733    -0.410  -0.501  -0.060  -0.154  -0.538-0.395    -0.312    -0.239     0.495     0.463     0.000     1.000\n",
      "   1.000   0.916     1.364     2.148   2.003   0.078  -0.035   0.934-0.395     3.207     4.191     0.495     0.754     1.000     1.000\n",
      "   1.000   0.602    -0.733    -1.627  -0.501  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.488     0.000     1.000\n",
      "   1.000  -2.005    -0.733    -1.749  -0.640  -0.060  -0.035  -0.538-0.395    -0.312    -0.239    -2.020     0.264     0.000     0.000\n",
      "   1.000   0.981    -0.733    -0.531   0.612   0.078  -0.094   0.934-0.395    -0.312    -0.239    -2.020     0.772     1.000     1.000\n",
      "   1.000  -1.469    -0.733     0.443   0.056  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.288     0.000     0.000\n",
      "   1.000  -1.130     1.364     1.661   0.264   0.009  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.335     0.000     0.000\n",
      "   1.000   1.026    -0.733    -0.288   0.682   0.078  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.624     1.000     1.000\n",
      "   1.000   0.293    -0.733    -1.506  -0.362   0.147   0.025   0.934 1.354    -0.312     4.191    -2.020     0.618     1.000     1.000\n",
      "   1.000   0.646    -0.733    -0.775   1.238   0.009  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.633     1.000     0.000\n",
      "   1.000  -2.063    -0.733    -1.140   0.404  -0.060  -0.094  -0.538-0.395    -0.312    -0.239     0.495     0.284     0.000     0.000\n",
      "   1.000  -0.217    -0.733     0.687   2.142   0.009  -0.035  -0.538-0.395    -0.312    -0.239     0.495     0.593     1.000     1.000\n",
      "   1.000  -1.042     1.364     0.687  -0.292  -0.060  -0.124  -0.538-0.395    -0.312     4.191     0.495     0.277     0.000     0.000\n",
      "   1.000   0.663    -0.733    -0.897  -0.779  -0.129  -0.154  -0.538-0.395    -0.312    -0.239     0.495     0.448     0.000     1.000\n",
      "   1.000   0.631    -0.733    -0.897  -0.709   0.009  -0.094   2.407 3.103    -0.312    -0.239     0.495     0.702     1.000     1.000\n"
     ]
    }
   ],
   "source": [
    "# inicializamos nuestra y_predicha_reg donde almacenaremos nuestras y predichas\n",
    "y_predicha_reg = []\n",
    "\n",
    "# calculamos la Y predicha de cada fila de X_test_ready_reg\n",
    "for i in X_test_ready_reg:\n",
    "  y_predicha_reg.append(sigmoid(np.dot(i, theta_reg)))\n",
    "\n",
    "\n",
    "y_predicha_reg = np.array(y_predicha_reg)\n",
    "\n",
    "# Usando el umbral donde todo valor que sea >= 0.5 sera 1 o al contrario es 0\n",
    "y_umbral_reg = (y_predicha_reg >= 0.5).astype(int)\n",
    "\n",
    "print(\"{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}\".format(\n",
    "    'X[:, 0]','X[:, 1]','X[:, 2]','X[:, 3]','X[:, 4]','X[:, 5]','X[:, 6]','X[:, 7]','X[:, 8]','X[:, 9]',\n",
    "    'X[:, 10]','X[:, 11]', ' Y_predicha', 'Y_umbral', ' Y_test'\n",
    "))\n",
    "\n",
    "print(\"=\" * 175)\n",
    "\n",
    "for i in range(30):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:6.3f}{:10.3f}{:10.3f}{:10.3f}{:10.3f}{:10.3f}{:10.3f}'.format(\n",
    "        X_test_ready_reg[i, 0], X_test_ready_reg[i, 1], X_test_ready_reg[i, 2], X_test_ready_reg[i, 3], X_test_ready_reg[i, 4], X_test_ready_reg[i, 5], X_test_ready_reg[i, 6],\n",
    "        X_test_ready_reg[i, 7], X_test_ready_reg[i, 8], X_test_ready_reg[i, 9], X_test_ready_reg[i, 10], X_test_ready_reg[i, 11],\n",
    "        y_predicha_reg[i], y_umbral_reg[i], y_test_reg.iloc[i]\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos que tal de precición tiene los datos de entrenamiento\n",
    "\n",
    "Calculamos con el metodo np.mean, la media(promedio) de los valores booleanos. Donde True se considera como 1 y False como 0 en operaciones aritméticas, la media resultante será la proporción de los elementos iguales en y_predicha e y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precición de entrenamiento: 65.26 % \n"
     ]
    }
   ],
   "source": [
    "# Mostramos la precición de entrenamiento\n",
    "print(\"Precición de entrenamiento: {:.2f} % \".format(np.mean(y_umbral_reg == y_test_reg) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Al concluir con los resultados del modelo de regresión logística se pudo observar que con la regularización se mejoró las pruebas con una pequeña diferencia en la parte de la presición que fue 65% con la regularización y 62% para la normal sin regularización.\n",
    "\n",
    "Pero como resultado la mejor experiencia fue aplicar la regularización para un buen entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
