{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimaciones finales de las recompensas: [-0.21185846  1.06908306 -0.45094464 -1.24867455  0.26751951]\n",
      "Valores verdaderos de las recompensas: [-0.5920272   1.05459843 -0.99168474 -1.42616414  0.24145076]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class WhacAMole:\n",
    "    def __init__(self, n_moles=5, epsilon=0.1):\n",
    "        self.n_moles = n_moles\n",
    "        self.epsilon = epsilon\n",
    "        self.q_true = np.random.randn(n_moles)  # Valores verdaderos de recompensa para cada topo\n",
    "        self.q_estimates = np.zeros(n_moles)  # Estimaciones iniciales de las recompensas\n",
    "        self.action_counts = np.zeros(n_moles)  # Conteo de veces que se ha elegido cada topo\n",
    "\n",
    "    def choose_action(self):\n",
    "        # Estrategia ε-Greedy\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_moles)  # Exploración\n",
    "        else:\n",
    "            return np.argmax(self.q_estimates)  # Explotación\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        # Recompensa obtenida es un valor aleatorio alrededor del valor verdadero\n",
    "        return np.random.randn() + self.q_true[action]\n",
    "\n",
    "    def update_estimates(self, action, reward):\n",
    "        self.action_counts[action] += 1\n",
    "        # Actualización incremental de la estimación del valor de acción\n",
    "        self.q_estimates[action] += (reward - self.q_estimates[action]) / self.action_counts[action]\n",
    "\n",
    "    def play(self, steps=1000):\n",
    "        rewards = np.zeros(steps)\n",
    "        for t in range(steps):\n",
    "            action = self.choose_action()\n",
    "            reward = self.get_reward(action)\n",
    "            self.update_estimates(action, reward)\n",
    "            rewards[t] = reward\n",
    "        return rewards\n",
    "\n",
    "# Ejecución del juego\n",
    "game = WhacAMole()\n",
    "rewards = game.play(steps=1000)\n",
    "\n",
    "print(\"Estimaciones finales de las recompensas:\", game.q_estimates)\n",
    "print(\"Valores verdaderos de las recompensas:\", game.q_true)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
